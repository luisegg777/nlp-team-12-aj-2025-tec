{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## MaestrÃ­a en Inteligencia Artificial Aplicada\n",
        "#### TecnolÃ³gico de Monterrey\n",
        "#### Prof Luis Eduardo FalcÃ³n Morales\n",
        "\n",
        "### **Adtividad en Equipos: sistema LLM + RAG**"
      ],
      "metadata": {
        "id": "-hVND8xY2OKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Nombres y matrÃ­culas:**\n",
        "\n",
        "  * Fernando Omar Salazar Ortiz - A01796214\n",
        "  * Carlos Aaron Bocanegra Buitron - A01796345\n",
        "  * Luis Enrique GonzÃ¡lez GonzÃ¡lez - A01795338\n",
        "  * Gloria MarÃ­a Campos GarcÃ­a - A01422345\n",
        "\n",
        "* **NÃºmero de Equipo: 12**\n"
      ],
      "metadata": {
        "id": "aimHVFOv23lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ##### **El formato de este cuaderno de Jupyter es libre, pero debe incuir al menos las siguientes secciones:**\n",
        "\n",
        "  * ##### **IntroducciÃ³n de la problemÃ¡tica a resolver.**\n",
        "  * ##### **Sistema RAG + LLM**\n",
        "  * ##### **El chatbot, incluyendo ejemplos de prueba.**\n",
        "  * ##### **Conclusiones**\n",
        "\n",
        "* ##### **Pueden importar los paquetes o librerÃ­as que requieran.**\n",
        "\n",
        "* ##### **Pueden incluir las celdas y lÃ­neas de cÃ³digo que deseen.**"
      ],
      "metadata": {
        "id": "7jimvsiVgjMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "google_drive_path_parent = \"/content/drive/MyDrive/Colab Notebooks/NLP/Actividades/ActividadSemana9_Chatbot_LLM_RAG/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFi0kXx9dJ1c",
        "outputId": "15028607-2a17-41d0-e792-feeb99e50665"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se hacen las instalaciones necesarias\n",
        "!pip install -q openai pymupdf sentence-transformers faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSqkHTMObLRg",
        "outputId": "f502c14a-3f33-447e-b279-d3ebdd5a5d5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m845.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se hacen las importaciones necesarias\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import fitz #PyMuPDF\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "Bfs5Zxc9j7Uf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga la API Key de OpenAI\n",
        "api_key = userdata.get(\"OPENAI_API_KEY_PERSONAL\")\n",
        "\n",
        "if not api_key:\n",
        "  raise ValueError(\"API key no encontrada en los secretos\")\n",
        "\n",
        "client = openai.OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "eTw6-9mxcLdj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(\n",
        "    pdf_path,\n",
        "    use_blocks=True,\n",
        "    min_length=40,\n",
        "    exclude_headers_footers=True,\n",
        "    header_height=60,\n",
        "    footer_height=60,\n",
        "    skip_pages=None,\n",
        "    start_at_page=0,\n",
        "    stop_at_page=None,\n",
        "    omit_texts=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Extrae texto de un PDF usando PyMuPDF, ordenando bloques visuales y controlando\n",
        "    rango de pÃ¡ginas y omisiÃ³n de textos especÃ­ficos.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Ruta del archivo PDF.\n",
        "        use_blocks (bool): Si True, extrae texto por bloques visuales; si False, por pÃ¡gina completa.\n",
        "        min_length (int): Longitud mÃ­nima para conservar un bloque.\n",
        "        exclude_headers_footers (bool): Si True, excluye encabezado y pie de pÃ¡gina.\n",
        "        header_height (int): Altura desde arriba a excluir (en puntos).\n",
        "        footer_height (int): Altura desde abajo a excluir (en puntos).\n",
        "        skip_pages (List[int] or None): Ãndices de pÃ¡ginas (base 0) a omitir.\n",
        "        start_at_page (int): PÃ¡gina inicial (Ã­ndice base 0) para empezar a procesar.\n",
        "        stop_at_page (int or None): Ãndice de pÃ¡gina en la que se debe detener el procesamiento.\n",
        "        omit_texts (List[str] or None): Lista de textos exactos a omitir (case-insensitive, strip).\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Lista de chunks de texto extraÃ­dos del PDF.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_chunks = []\n",
        "    skip_pages = skip_pages or []\n",
        "    omit_texts = [t.strip().lower() for t in (omit_texts or [])]\n",
        "\n",
        "    # Itera desde start_at_page hasta stop_at_page (no inclusivo)\n",
        "    page_range = range(start_at_page, stop_at_page if stop_at_page is not None else len(doc))\n",
        "\n",
        "    for i in page_range:\n",
        "        if i in skip_pages:\n",
        "            continue\n",
        "\n",
        "        page = doc[i]\n",
        "        page_height = page.rect.height\n",
        "\n",
        "        if use_blocks:\n",
        "            blocks = page.get_text(\"blocks\")\n",
        "            blocks = sorted(blocks, key=lambda b: (b[1], b[0]))\n",
        "            for b in blocks:\n",
        "                x0, y0, x1, y1, text = b[:5]\n",
        "                if not text or len(text.strip()) < min_length:\n",
        "                    continue\n",
        "                if exclude_headers_footers and (y0 < header_height or y1 > page_height - footer_height):\n",
        "                    continue\n",
        "                clean_text = text.strip().lower()\n",
        "                if clean_text in omit_texts:\n",
        "                    continue\n",
        "                all_chunks.append(text.strip())\n",
        "        else:\n",
        "            text = page.get_text()\n",
        "            if text and len(text.strip()) >= min_length:\n",
        "                clean_text = text.strip().lower()\n",
        "                if clean_text not in omit_texts:\n",
        "                    all_chunks.append(text.strip())\n",
        "\n",
        "    return all_chunks\n",
        "\n",
        "\n",
        "def save_chunks_to_json(chunks, file_path=\"chunks.json\"):\n",
        "    \"\"\"\n",
        "    Guarda una lista de bloques de texto en un archivo JSON.\n",
        "    Cada lÃ­nea es un bloque, editable manualmente.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"âœ… Bloques guardados en {file_path}\")\n",
        "\n",
        "\n",
        "def load_chunks_from_json(file_path=\"chunks.json\"):\n",
        "    \"\"\"\n",
        "    Carga los bloques de texto desde un archivo JSON y devuelve una lista.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        chunks = json.load(f)\n",
        "    print(f\"ğŸ“„ Bloques cargados: {len(chunks)}\")\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def save_embeddings_to_pkl(vectors, chunks, file_path=\"embeddings_data.pkl\"):\n",
        "    \"\"\"\n",
        "    Guarda los vectores (embeddings) y sus textos (chunks) en un archivo .pkl.\n",
        "\n",
        "    Args:\n",
        "        vectors (List[List[float]] o np.ndarray): Embeddings generados.\n",
        "        chunks (List[str]): Lista de textos originales de cada embedding.\n",
        "        file_path (str): Ruta de archivo donde se guardarÃ¡ todo.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        \"vectors\": np.array(vectors).astype(\"float64\"),\n",
        "        \"chunks\": chunks\n",
        "    }\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "    print(f\"âœ… Embeddings guardados en {file_path}\")\n",
        "\n",
        "\n",
        "def load_embeddings_from_pkl(file_path=\"embeddings_data.pkl\"):\n",
        "    \"\"\"\n",
        "    Carga los vectores (embeddings) y los textos (chunks) desde un archivo .pkl.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, List[str]]: embeddings y chunks.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "    print(f\"ğŸ“‚ Cargados {len(data['chunks'])} embeddings desde {file_path}\")\n",
        "    return data[\"vectors\"], data[\"chunks\"]\n",
        "\n",
        "\n",
        "def embed_texts_openai(texts):\n",
        "    embeddings = []\n",
        "    for chunk in texts:\n",
        "        response = client.embeddings.create(\n",
        "            input=chunk,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        embedding = response.data[0].embedding\n",
        "        embeddings.append(embedding)\n",
        "    return np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = len(embeddings[0])\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index"
      ],
      "metadata": {
        "id": "BGUzhJ8Oc-GA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_and_answer_openai(\n",
        "    question,\n",
        "    chunks,\n",
        "    index,\n",
        "    chunk_embeddings,\n",
        "    top_k=5,\n",
        "    use_rag=True,\n",
        "    print_chunks=False\n",
        "):\n",
        "    if use_rag:\n",
        "        q_embedding = client.embeddings.create(\n",
        "            input=question,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        ).data[0].embedding\n",
        "        q_vector = np.array(q_embedding).astype(\"float32\").reshape(1, -1)\n",
        "        D, I = index.search(q_vector, top_k)\n",
        "        if print_chunks:\n",
        "            print(\"------------------------------------\")\n",
        "            for rank, idx in enumerate(I[0]):\n",
        "                print(f\"--- Chunk #{idx} --\")\n",
        "                print(f\"Distancia (D): {D[0][rank]} \\n\")\n",
        "                print(chunks[idx])\n",
        "            print(\"------------------------------------\")\n",
        "        context = \"\\n---\\n\".join([chunks[i] for i in I[0]])\n",
        "\n",
        "        prompt = f\"\"\"Usa la siguiente informaciÃ³n para responder la pregunta de forma clara y completa. Solo responde con base en la informaciÃ³n proporcionada, no busques datos en otras fuentes\n",
        "InformaciÃ³n:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "    else:\n",
        "        prompt = f\"\"\"Responde de forma clara y completa la siguiente pregunta sobre alimentaciÃ³n durante el embarazo. Si no tienes informaciÃ³n suficiente, dilo claramente.\n",
        "\n",
        "Pregunta: {question}\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        #model=\"gpt-3.5-turbo\",\n",
        "        model=\"o4-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"Eres un chatbot para resolver dudas de la alimentaciÃ³n durante el embarazo \"\n",
        "                    \"que responde en base a la informaciÃ³n proporcioanda de contexto. \"\n",
        "                    \"Si la informaciÃ³n no es suficiente, entonces dices que no puedes responder esa pregunta.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "F9Ofr4-AwMwU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROCESAMIENTO\n",
        "\n",
        "pdf_path = google_drive_path_parent + \"guia-alimentaria-mujeres-embarazadas.pdf\"\n",
        "chunks = extract_text_from_pdf(\n",
        "    pdf_path=pdf_path,\n",
        "    use_blocks=True,\n",
        "    min_length=3,\n",
        "    exclude_headers_footers=True,\n",
        "    header_height=0,\n",
        "    footer_height=50,\n",
        "    skip_pages=[],\n",
        "    start_at_page=6,\n",
        "    stop_at_page=78,\n",
        "    omit_texts=[\"Â¿CÃ“MO ESTAMOS EN MÃ‰XICO?\",\n",
        "                \"Â¿POR QUÃ‰ ES IMPORTANTE ESTA RECOMENDACIÃ“N?\",\n",
        "                \"En la salud:\",\n",
        "                \"En las mujeres:\",\n",
        "                \"En las y los bebÃ©s:\",\n",
        "                \"En la cultura y en la sociedad:\",\n",
        "                \"En el ambiente:\",\n",
        "                \"En la economÃ­a, en la cultura y en la sociedad:\",\n",
        "                \"En el o la bebÃ© gestante\",\n",
        "                \"En mujeres embarazadas:\",\n",
        "                \"En mujeres en periodo de lactancia y posparto:\",\n",
        "                \"En las y los reciÃ©n nacidos:\",\n",
        "                \"ORIENTE SOBRE CÃ“MO PONER EN PRÃCTICA \\nLA RECOMENDACIÃ“N, MENCIONANDO QUE:\",\n",
        "                ]\n",
        ")"
      ],
      "metadata": {
        "id": "WmudszGrdFAC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii0K_ZwdlWd8",
        "outputId": "e421d37b-4401-45dd-da71-6e9673a0ba9e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save_chunks_to_json(chunks=chunks, file_path=\"/content/drive/MyDrive/Colab Notebooks/NLP/Actividades/ActividadSemana9_Chatbot_LLM_RAG/chunks.json\")\n",
        "save_chunks_to_json(chunks=chunks, file_path= google_drive_path_parent + \"chunks.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvXOCsQIdkJ5",
        "outputId": "52ceef5e-03b2-4430-b040-0f24d894319a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Bloques guardados en /content/drive/MyDrive/Colab Notebooks/NLP/Actividades/ActividadSemana9_Chatbot_LLM_RAG/chunks.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks2 =load_chunks_from_json(file_path=google_drive_path_parent + \"chunks_cambios_manuales.json\")\n",
        "#Los cambios manuales que hicieron fueron eliminar la informaciÃ³n correspondiente a las tablas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f1vHraKSuHAZ",
        "outputId": "1e4d5069-780f-4188-fd83-bc260c6aabc0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Bloques cargados: 293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se generan los embeddings\n",
        "#embeddings = embed_texts_openai(chunks2)"
      ],
      "metadata": {
        "id": "ylsgt-GvukxB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_embeddings_to_pkl(embeddings, chunks2, file_path=google_drive_path_parent + \"embeddings_guia_alimentaria.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIyaHzkJvaeT",
        "outputId": "5f81ce45-60e8-4bd1-f344-cc1d1a815659"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Embeddings guardados en /content/drive/MyDrive/Colab Notebooks/NLP/Actividades/ActividadSemana9_Chatbot_LLM_RAG/embeddings_guia_alimentaria.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings, chunks2 =load_embeddings_from_pkl(file_path=google_drive_path_parent + \"embeddings_guia_alimentaria.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iroa0HVGv6jR",
        "outputId": "c4239e3f-0daf-48bb-86dd-d5d4d51f8b60"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Cargados 293 embeddings desde /content/drive/MyDrive/Colab Notebooks/NLP/Actividades/ActividadSemana9_Chatbot_LLM_RAG/embeddings_guia_alimentaria.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea el indice\n",
        "faiss_index = create_faiss_index(embeddings)"
      ],
      "metadata": {
        "id": "JPsPbJHju-It"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pregunta = \"Â¿Se puede consumir cafÃ© durante el embarazo?\"\n",
        "#pregunta = \"Â¿Se puede consumir alcohol durante el embarazo?\"\n",
        "#pregunta = \"Â¿CuÃ¡nta agua se debe consumir durante el embarazo\"\n",
        "#pregunta = \"Â¿QuÃ© alimentos y bebidas se deben evitar durante el embarazo?\"\n",
        "#pregunta = \"Â¿cuÃ¡ntas leguminosas se recomienda consumir durante el embarazo?\"\n",
        "#pregunta = \"Â¿QuÃ© frutas puedo comer durante el embarazo?\" # No tiene buenos resultados esta pregunta\n",
        "#pregunta = \"Â¿QuÃ© cereales debo comer durante el embarazo?\"\n",
        "#pregunta = \"Â¿Puedo comer carne de pescado?\"\n",
        "#pregunta = \"Â¿Puedo comer elote?\"\n",
        "pregunta = \"Â¿Puedo comer frutos rojos, como fresas, zarzamoras, arandanos, etc.?\"\n",
        "#respuesta = retrieve_and_answer(pregunta, chunks, faiss_index, embeddings)\n",
        "respuesta = retrieve_and_answer_openai(pregunta, chunks2, faiss_index, embeddings, use_rag=True, print_chunks=True)\n",
        "print(\"\\nğŸ¤– Respuesta del chatbot:\\n\", respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq035boJwHW_",
        "outputId": "24eeba2a-b66f-464d-b58d-ff5a7095104a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------\n",
            "--- Chunk #66 --\n",
            "Distancia (D): 0.9339300990104675 \n",
            "\n",
            "Pruebe congelar tus frutas \n",
            "favoritas, ya sea plÃ¡tano, \n",
            "fresas o uvas, entre otras.\n",
            "--- Chunk #65 --\n",
            "Distancia (D): 0.9717541337013245 \n",
            "\n",
            "Incluya frutas de temporada, tanto \n",
            "en el desayuno, los refrigerios o en \n",
            "cualquier momento del dÃ­a en el que \n",
            "tenga hambre o antojo de algo dulce.\n",
            "--- Chunk #71 --\n",
            "Distancia (D): 0.988568902015686 \n",
            "\n",
            "Evite consumir frutas con azÃºcar, miel, en almÃ­bar \n",
            "o con grasas aÃ±adidas como crema o media\n",
            "crema. Si las consume, que sea ocasionalmente.\n",
            "--- Chunk #64 --\n",
            "Distancia (D): 1.0223766565322876 \n",
            "\n",
            "PARA COMER MÃS FRUTAS\n",
            "--- Chunk #136 --\n",
            "Distancia (D): 1.0291736125946045 \n",
            "\n",
            "Recuerde no exceder el consumo de carnes rojas y evitar las carnes procesadas.\n",
            "------------------------------------\n",
            "\n",
            "ğŸ¤– Respuesta del chatbot:\n",
            " SÃ­. Los frutos rojos (fresas, zarzamoras, arÃ¡ndanos, etc.) son una excelente opciÃ³n de fruta. Para aprovecharlos al mÃ¡ximo:\n",
            "\n",
            "1. CongÃ©lalos: puedes picarlos y meterlos al congelador para tener un snack frÃ­o y cremoso sin aÃ±adir azÃºcares.  \n",
            "2. IncorpÃ³ralos en tu desayuno o refrigerios: agrÃ©galos a tu yogurt natural, avena o licuados. TambiÃ©n funcionan como colaciÃ³n entre comidas cuando tengas antojo de algo dulce.  \n",
            "3. Evita acompaÃ±arlos con azÃºcar, miel, almÃ­bar o cremas grasas. Si los quieres con algo extra (por ejemplo, crema), hazlo de forma muy ocasional.\n",
            "\n",
            "De este modo disfrutarÃ¡s de sus nutrientes y sabor sin excederte en azÃºcares o grasas aÃ±adidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusiones:**"
      ],
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad chatbot LLM + RAG:**\n",
        "\n",
        "\n",
        "\n",
        "None"
      ],
      "metadata": {
        "id": "3w3usdaC0BCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fin de la actividad chatbot: LLM + RAG**"
      ],
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      }
    }
  ]
}