{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## MaestrÃ­a en Inteligencia Artificial Aplicada\n",
        "#### TecnolÃ³gico de Monterrey\n",
        "#### Prof Luis Eduardo FalcÃ³n Morales\n",
        "\n",
        "### **Adtividad en Equipos: sistema LLM + RAG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrÃ­culas:**\n",
        "\n",
        "  * Fernando Omar Salazar Ortiz - A01796214\n",
        "  * Carlos Aaron Bocanegra Buitron - A01796345\n",
        "  * Luis Enrique GonzÃ¡lez GonzÃ¡lez - A01795338\n",
        "  * Gloria MarÃ­a Campos GarcÃ­a - A01422345\n",
        "\n",
        "* **NÃºmero de Equipo:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jimvsiVgjMg"
      },
      "source": [
        "* ##### **El formato de este cuaderno de Jupyter es libre, pero debe incuir al menos las siguientes secciones:**\n",
        "\n",
        "  * ##### **IntroducciÃ³n de la problemÃ¡tica a resolver.**\n",
        "  * ##### **Sistema RAG + LLM**\n",
        "  * ##### **El chatbot, incluyendo ejemplos de prueba.**\n",
        "  * ##### **Conclusiones**\n",
        "\n",
        "* ##### **Pueden importar los paquetes o librerÃ­as que requieran.**\n",
        "\n",
        "* ##### **Pueden incluir las celdas y lÃ­neas de cÃ³digo que deseen.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q openai\n",
        "!pip install -q openai PyPDF2 sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se hacen las importaciones necesarias\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import PyPDF2\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Guarda los vectores (embeddings) y sus textos (chunks) en un archivo .pkl.\n",
        "\n",
        "Args:\n",
        "    vectors (List[List[float]] o np.ndarray): Embeddings generados.\n",
        "    chunks (List[str]): Lista de textos originales de cada embedding.\n",
        "    file_path (str): Ruta de archivo donde se guardarÃ¡ todo.\n",
        "\"\"\"\n",
        "def save_embeddings_to_pkl(vectors, chunks, file_path=\"embeddings_data.pkl\"):\n",
        "    data = {\n",
        "        \"vectors\": np.array(vectors).astype(\"float64\"),\n",
        "        \"chunks\": chunks\n",
        "    }\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "    print(f\"âœ… Embeddings guardados en {file_path}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Carga los vectores (embeddings) y los textos (chunks) desde un archivo .pkl.\n",
        "\n",
        "Returns:\n",
        "    Tuple[np.ndarray, List[str]]: embeddings y chunks.\n",
        "\"\"\"\n",
        "def load_embeddings_from_pkl(file_path=\"embeddings_data.pkl\"):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "    print(f\"ðŸ“‚ Cargados {len(data['chunks'])} embeddings desde {file_path}\")\n",
        "    return data[\"vectors\"], data[\"chunks\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bfs5Zxc9j7Uf"
      },
      "outputs": [],
      "source": [
        "# Se carga la API Key de OpenAI\n",
        "\n",
        "\n",
        "api_key = userdata.get(\"OPENAI_API_KEY_PERSONAL\")\n",
        "\n",
        "\n",
        "\n",
        "if not api_key:\n",
        "  raise ValueError(\"API key no encontrada en los secretos\")\n",
        "\n",
        "\n",
        "client = openai.OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. EXTRAER TEXTO DEL PDF\n",
        "def extract_text_from_pdf(pdf_path, skip_pages=None):\n",
        "    if skip_pages is None:\n",
        "        skip_pages = []\n",
        "\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "\n",
        "        for i, page in enumerate(reader.pages):\n",
        "            if i in skip_pages:\n",
        "                continue  # Salta la pÃ¡gina\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# 2. DIVIDIR EN CHUNKS DE ~500 TOKENS\n",
        "def chunk_text(text, max_tokens=500, overlap=100):\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = enc.encode(text)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = min(start + max_tokens, len(tokens))\n",
        "        chunk = enc.decode(tokens[start:end])\n",
        "        chunks.append(chunk)\n",
        "        start += max_tokens - overlap\n",
        "    return chunks\n",
        "\n",
        "# 3. GENERAR EMBEDDINGS \n",
        "def embed_texts(texts):\n",
        "    embeddings = []\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    embeddings = model.encode(texts)\n",
        "    return np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "\n",
        "def embed_texts_openai(texts):\n",
        "    embeddings = []\n",
        "    for chunk in texts:\n",
        "        response = client.embeddings.create(\n",
        "            input=chunk,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        embedding = response.data[0].embedding\n",
        "        embeddings.append(embedding)\n",
        "    return np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "# 4. Crear indice FAISS\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = len(embeddings[0])\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index\n",
        "\n",
        "# 4. RAG: RECUPERAR Y GENERAR RESPUESTA\n",
        "def retrieve_and_answer(question, chunks, index, chunk_embeddings, top_k=3):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    q_embedding = model.encode(question)\n",
        "     \n",
        "    q_vector = np.array(q_embedding).astype(\"float32\").reshape(1, -1)\n",
        "    D, I = index.search(q_vector, top_k)\n",
        "    print(\"------------------------------------\")\n",
        "    for rank, idx in enumerate(I[0]):\n",
        "        print(f\"\\n--- Chunk #{idx} --\")\n",
        "        print(f\"Distancia (D): {D[0][rank]} \\n\")\n",
        "        print(chunks[idx])\n",
        "        \n",
        "\n",
        "    print(\"------------------------------------\")\n",
        "    context = \"\\n---\\n\".join([chunks[i] for i in I[0]])\n",
        "    '''\n",
        "    prompt = f\"\"\"Usa la siguiente informaciÃ³n para responder la pregunta de forma clara y completa.\n",
        "InformaciÃ³n:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "    '''\n",
        "    return \"TEST\"\n",
        "\n",
        "\n",
        "def retrieve_and_answer_openai(question, chunks, index, chunk_embeddings, top_k=3):\n",
        "    q_embedding = client.embeddings.create(\n",
        "                                            input=question,\n",
        "                                            model=\"text-embedding-3-small\"\n",
        "                                        ).data[0].embedding\n",
        "    q_vector = np.array(q_embedding).astype(\"float32\").reshape(1, -1)\n",
        "    D, I = index.search(q_vector, top_k)\n",
        "    print(\"------------------------------------\")\n",
        "    for rank, idx in enumerate(I[0]):\n",
        "        print(f\"--- Chunk #{idx} --\")\n",
        "        print(f\"Distancia (D): {D[0][rank]} \\n\")\n",
        "        print(chunks[idx])\n",
        "    print(\"------------------------------------\")\n",
        "    return \"TEST\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. FLUJO COMPLETO\n",
        "pdf_path = \"lwc-pregnancy-guide_spanish-1.pdf\"  # Reemplaza con tu archivo\n",
        "text = extract_text_from_pdf(pdf_path, skip_pages=[0, 1, 22, 23, 24])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks = chunk_text(text, max_tokens=200, overlap=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "#embeddings = embed_texts(chunks)\n",
        "embeddings = embed_texts_openai(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "faiss_index = create_faiss_index(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "--- Chunk #37 --\n",
            "Distancia (D): 0.7017810344696045 \n",
            "\n",
            " despuÃ©s del sexo, puede ser Ãºtil usar \n",
            "condÃ³n. El semen humano contiene hormonas que pueden causar contracciones. La mayorÃ­a de las parejas tendrÃ¡n cambios en \n",
            "sus patrones sexuales o libido durante el embarazo. MÃ¡s que nunca, es importante que haya comprensiÃ³n mutua y comunicaciÃ³n \n",
            "abierta. Puede que usted necesite explorar mÃ©todos nuevos para complacerse el uno al otro. La mujer embarazada puede tener \n",
            "un orgasmo sin peligro. \n",
            "Viajar\n",
            "Su mejor guÃ­a serÃ¡ el sentido comÃºn. Si va a viajar una distancia larga, se encontrarÃ¡ mÃ¡s cÃ³moda si usted se permite estirar, \n",
            "caminar, y vaciar la vejiga cada dos horas. EstÃ¡ bien viajar en aviÃ³n, pero algunas aerolÃ­neas exigen un permiso escrito por su \n",
            "doctor si viaja durante el Ãºltimo trimestre. Durante el Ãºltimo mes de\n",
            "--- Chunk #38 --\n",
            "Distancia (D): 0.7457499504089355 \n",
            "\n",
            "igen un permiso escrito por su \n",
            "doctor si viaja durante el Ãºltimo trimestre. Durante el Ãºltimo mes de su embarazo serÃ­a prudente quedarse cerca de casa. Si ha \n",
            "tenido alguna complicaciÃ³n durante su embarazo o tiene factores de riesgo que se pueden complicar, usted deberÃ­a hablar con \n",
            "su doctor sobre sus planes de viaje antes de realizarlos.\n",
            "LWC Su GuÃ­a Para El Embarazo  PÃGINA 9Toxoplasmosis\n",
            "La toxoplasmosis es una enfermedad causada por un organismo comÃºn que se encuentra en nuestro medio ambiente. Si \n",
            "una mujer se infecta por primera vez durante el embarazo, puede tener graves consecuencias para el bebÃ©. Por tal motivo, le \n",
            "sugerimos que tome algunas precauciones simples. No coma carne cruda o poco cocida y evite carne de venado. Al parecer el \n",
            "comer carne es\n",
            "--- Chunk #40 --\n",
            "Distancia (D): 0.7999102473258972 \n",
            "\n",
            " EJERCICIO\n",
            "La mayorÃ­a de sus actividades diarias se pueden llevar a cabo durante el embarazo. Si usted corre o trota regularmente, no hay \n",
            "necesidad de parar. Usted notarÃ¡ que se fatiga fÃ¡cilmente y a medida que progrese el embarazo estarÃ¡ mÃ¡s propensa a perder el \n",
            "equilibrio. Por lo tanto, patinar, esquiar, montar a caballo o cualquier actividad que pueda provocar una caÃ­da no debe realizarse. \n",
            "El ejercicio ayuda a mejorar la postura, mejorar la circulaciÃ³n, aliviar molestias menores y producir una sensaciÃ³n de \n",
            "bienestar. Mantenerse en forma le ayudarÃ¡ a responder mejor al estrÃ©s del parto. Debido a los cambios fÃ­sicos normales \n",
            "del embarazo, ciertos movimientos o posiciones no son recomendados. Haga referencia a las recomendaciones incluidas a \n",
            "continuaciÃ³n\n",
            "------------------------------------\n",
            "\n",
            "ðŸ¤– Respuesta del chatbot:\n",
            " TEST\n"
          ]
        }
      ],
      "source": [
        "#pregunta = \"Â¿Se puede consumir cafeÃ­na durante el embarazo?\"\n",
        "#pregunta = \"Â¿QuÃ© son las vitaminas prenatales?\"\n",
        "#pregunta = \"Â¿Todas las mujeres deben de tomar vitaminas prenatales durante el embarazo?\"\n",
        "#pregunta = \"Â¿QuÃ© frutas puedo comer durante el embarazo?\" # No tiene buenos resultados esta pregunta\n",
        "pregunta = \"Â¿Se puede viajar durante el embarazo?\"\n",
        "#respuesta = retrieve_and_answer(pregunta, chunks, faiss_index, embeddings)\n",
        "respuesta = retrieve_and_answer_openai(pregunta, chunks, faiss_index, embeddings)\n",
        "print(\"\\nðŸ¤– Respuesta del chatbot:\\n\", respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Embeddings guardados en embeddings_test_lwc_pdf.pkl\n"
          ]
        }
      ],
      "source": [
        "save_embeddings_to_pkl(embeddings, chunks, file_path='embeddings_test_lwc_pdf.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ Cargados 105 embeddings desde embeddings_test_lwc_pdf.pkl\n"
          ]
        }
      ],
      "source": [
        "vectors, texts =load_embeddings_from_pkl(file_path='embeddings_test_lwc_pdf.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia: 1.0078504085540771\n"
          ]
        }
      ],
      "source": [
        "#import numpy as np\n",
        "\n",
        "def l2_distance(a, b):\n",
        "    return np.linalg.norm(a - b)\n",
        "\n",
        "# Comparar con, por ejemplo, el chunk #17\n",
        "question = \"Â¿QuÃ© son las vitaminas prenatales?\"\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "q_embedding = model.encode(question)\n",
        "\n",
        "distance = l2_distance(q_embedding, embeddings[27])\n",
        "print(f\"Distancia: {distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      },
      "source": [
        "# **Conclusiones:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3usdaC0BCj"
      },
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad chatbot LLM + RAG:**\n",
        "\n",
        "\n",
        "\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      },
      "source": [
        "# **Fin de la actividad chatbot: LLM + RAG**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
