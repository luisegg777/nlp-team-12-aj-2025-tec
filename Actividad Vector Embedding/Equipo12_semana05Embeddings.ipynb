{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl8G3vHkPSX"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Adtividad Semana 5\n",
        "\n",
        "### **Vectores Embebidos de OpenAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U69mHA6i201G"
      },
      "source": [
        "#### **Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "\n",
        "* Fernando Omar Salazar Ortiz - A01796214\n",
        "* Carlos Aaron Bocanegra Buitron - A01796345\n",
        "* Luis Enrique González González - A01795338\n",
        "* Gloria María Campos García - A01422345\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yZqVdvuHhPJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d40b3f3-78f8-4df5-8c6d-a86b00e1d95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wCL2p6MA8NuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1b73c4-57c0-4fb6-e85e-33aa4521fab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')    # para tener acceso a \"stopwords\" en varios idiomas.\n",
        "\n",
        "import spacy #Para aplicar la lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7wc107K-oIV4"
      },
      "outputs": [],
      "source": [
        "# Incluye las celdas necesarias para tu acceso a la API de OpenAI.\n",
        "\n",
        "api_key = userdata.get(\"openapikey\")\n",
        "\n",
        "if not api_key:\n",
        "  raise ValueError(\"API key no encontrada en los secretos\")\n",
        "\n",
        "client = OpenAI(api_key = api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c34ZOnna3Gu"
      },
      "source": [
        "# **Pregunta - 1:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeNllxRdmeWg"
      },
      "source": [
        "Descarga los 3 archivos de Canvas y genera un nuevo DataFrame de Pandas con ellos.\n",
        "\n",
        "**Llama simplemente \"df\" a dicho DataFrame.**\n",
        "\n",
        "Los archivos los encuentras en Canvas: amazon5.txt, imdb5.txt, yelp5.txt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T_lyEFRkxzC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefefd3a-af73-4771-e181-ae74491ae205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros de Amazon: (1000, 2)\n",
            "Total de registros de IMBD: (1000, 2)\n",
            "Total de registros de Yelp: (1000, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/MNA/NLP/Semana5')\n",
        "\n",
        "dfa = pd.read_csv('amazon5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfi = pd.read_csv('imdb5.txt', sep=r'\\s{3,}', names=['review','label'], header=None, encoding='utf-8', engine='python')\n",
        "dfy = pd.read_csv('yelp5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "\n",
        "#Total de registros\n",
        "print('Total de registros de Amazon:',dfa.shape)\n",
        "print('Total de registros de IMBD:',dfi.shape)\n",
        "print('Total de registros de Yelp:',dfy.shape)\n",
        "\n",
        "df = pd.concat([dfa, dfi, dfy], ignore_index=True)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3-w1xMLYnm9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be63877-d85c-406c-ea96-4693b6a60edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  3000 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Verifiquemos la información del DataFrame:\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se verifican los 3000 registros\n",
        "assert df.shape[0] == 3000\n",
        "#Se verifican las 2 columnas\n",
        "assert df.shape[1] == 2\n",
        "#Se verifica que no haya valores nulos\n",
        "assert df['review'].isnull().sum() == 0\n",
        "assert df['label'].isnull().sum() == 0"
      ],
      "metadata": {
        "id": "0qUGqhwR1hwC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NfVUcYe1nubT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "da78edb2-2815-4824-9bb2-a9a89d1a4ca4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3421ca19-d6a2-46b3-8689-59fc617f6724\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3421ca19-d6a2-46b3-8689-59fc617f6724')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3421ca19-d6a2-46b3-8689-59fc617f6724 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3421ca19-d6a2-46b3-8689-59fc617f6724');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-69aed6b3-5937-40c0-b6b6-e4c5bb6fe386\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69aed6b3-5937-40c0-b6b6-e4c5bb6fe386')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-69aed6b3-5937-40c0-b6b6-e4c5bb6fe386 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2982,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.\",\n          \"It was that loud.Glad to say that the Plantronics 510 maintains a flawless connection to my cell and with no static during normal use.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Y veamos sus primeros registros:\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfZZ0stLmWJN"
      },
      "source": [
        "# **Pregunta - 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F6JF5BommZ6"
      },
      "source": [
        "Realiza el proceso de limpieza. Aplica el preprocesamiento que consideres adecuado.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TsnvMp-7oYCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "def clean_tok(doc):\n",
        "\n",
        "  #Convertir a minusculas\n",
        "  docTmp = doc.lower()\n",
        "\n",
        "  #Sustitucion de negaciones estilo don't por do not\n",
        "\n",
        "  contractions = {\n",
        "    r\"don't\": \"do not\",\n",
        "    r\"dont\": \"do not\",\n",
        "    r\"doesn't\": \"does not\",\n",
        "    r\"didn't\": \"did not\",\n",
        "    r\"can't\": \"can not\",\n",
        "    r\"cant\": \"can not\",\n",
        "    r\"couldn't\": \"could not\",\n",
        "    r\"won't\": \"will not\",\n",
        "    r\"wouldn't\": \"would not\",\n",
        "    r\"shouldn't\": \"should not\",\n",
        "    r\"mustn't\": \"must not\",\n",
        "    r\"mightn't\": \"might not\",\n",
        "    r\"needn't\": \"need not\",\n",
        "    r\"shan't\": \"shall not\",\n",
        "    r\"hasn't\": \"has not\",\n",
        "    r\"haven't\": \"have not\",\n",
        "    r\"hadn't\": \"had not\",\n",
        "    r\"wasn't\": \"was not\",\n",
        "    r\"weren't\": \"were not\",\n",
        "    r\"isn't\": \"is not\",\n",
        "    r\"aren't\": \"are not\",\n",
        "  }\n",
        "\n",
        "  for pattern, replacement in contractions.items():\n",
        "    docTmp = re.sub(pattern, replacement, docTmp)\n",
        "\n",
        "\n",
        "  #Reemplazar todos los caracteres no alfabeticos por espacios en blanco\n",
        "  docTmp2 = re.sub(r'[^a-z]', ' ', docTmp)\n",
        "\n",
        "\n",
        "  #Tokenizacion usando word_tokenize\n",
        "  tokensTmp = nltk.word_tokenize(docTmp2)\n",
        "\n",
        "  #Remover stopwords en ingles\n",
        "  # Consideremos la siguiente lista de palabras asociada a negaciones en ingles\n",
        "  negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "  mystopwords = [stopword for stopword in stopwords.words('english') if stopword not in negwords]\n",
        "  tokensTmp2 = [token for token in tokensTmp if token not in mystopwords]\n",
        "\n",
        "  tokens = tokensTmp2\n",
        "\n",
        "  return tokens\n",
        "\n",
        "\n",
        "def clean_doc(doc):\n",
        "  tokens = []\n",
        "\n",
        "  #procesamiento de SO\n",
        "  tmp = [re.sub(r'^[s]+[o]{2,}$', 'so', token) for token in doc]\n",
        "\n",
        "  #procesamiento de GOOD\n",
        "  tmp2 = [re.sub(r'^[g]+[o]{3,}[d]+$', 'good', token) for token in tmp]\n",
        "\n",
        "  #Reemplazar letras repetidas 3+ por una letra\n",
        "  tmp3 = [re.sub(r'(.)\\1{2,}', r'\\1', token) for token in tmp2]\n",
        "\n",
        "  #Aplicar Lemmatization\n",
        "  tmp4 = [nlp(token)[0].lemma_ for token in tmp3]\n",
        "\n",
        "  #tokens = tmp3\n",
        "  tokens = tmp4\n",
        "\n",
        "  #print(tokens)\n",
        "  return tokens\n",
        "\n",
        "\n",
        "\n",
        "# Separamos la información:\n",
        "#     La \"X\" serán los datos de entrada, los comentarios.\n",
        "#     La \"Y\" será la variable de salida, la evaluación.\n",
        "X = df.review\n",
        "Y = df.label\n",
        "\n",
        "\n",
        "\n",
        "Xcleantok = [clean_tok(x) for x in X]\n",
        "\n",
        "Xclean = [clean_doc(x) for x in Xcleantok]\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7jlQuoI2o33T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc49de52-7abf-408d-c1da-ed6572ee2b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no', 'way', 'plug', 'we', 'unless', 'go', 'converter']\n",
            "['good', 'case', 'excellent', 'value']\n",
            "['great', 'jawbone']\n",
            "['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problem']\n",
            "['mic', 'great']\n"
          ]
        }
      ],
      "source": [
        "# Despleguemos los primeros comentarios después de tu proceso de limpieza:\n",
        "\n",
        "# comment 27 had 'didn't'\n",
        "\n",
        "#for x in Xclean[27:28]:\n",
        "for x in Xclean[0:5]:\n",
        "  print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygchEdcKqIzU"
      },
      "source": [
        "# **Pregunta - 3:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEIOkkl9Dot"
      },
      "source": [
        "\n",
        "Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de\n",
        "esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b0SAcYdq9X0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dda4e5d-86b2-443f-b63f-892c6a0b3577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ************* Inicia la sección de agregar código:*****************************\n",
        "\n",
        "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "\n",
        "# *********** Termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "print('X,y Train:', len(x_train), len(y_train))\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))\n",
        "\n",
        "#Se valida la cantidad de registros\n",
        "assert len(x_train) == len(y_train) == 2100\n",
        "assert len(x_val) == len(y_val) == 450\n",
        "assert len(x_test) == len(y_test) == 450"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qjKoEqiqBN1"
      },
      "source": [
        "# **Pregunta - 4:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jENsKiN99r3F"
      },
      "source": [
        "\n",
        "\n",
        "Construye tu vocabulario a continuación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TzJntmLPqPqC"
      },
      "outputs": [],
      "source": [
        "# a.\tUsa el conjunto de entrenamiento para generar tu vocabulario\n",
        "#     con un tamaño que consideres adecuado:\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def get_filtered_vocabulary(comments, min_freq=2, min_word_length=2):\n",
        "    filtered_comments = [\n",
        "        [token for token in comment if len(token) >= min_word_length]\n",
        "        for comment in comments\n",
        "    ]\n",
        "\n",
        "    token_counter = Counter()\n",
        "    for comment in filtered_comments:\n",
        "        token_counter.update(comment)\n",
        "\n",
        "    filtered_vocab = {\n",
        "        token: freq for token, freq in token_counter.items() if freq >= min_freq\n",
        "    }\n",
        "\n",
        "    return filtered_vocab\n",
        "\n",
        "midicc = get_filtered_vocabulary(x_train, min_freq=1, min_word_length=2)\n",
        "#print(dictionary)\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Se eligió la frecuencia mínima de 1 para incluir los comentarios que despues de su proceso de limpieza solamente quedaron con 1 token.\n",
        "2. Se eligió el tamaño de token a 2 caracteres porque hay muy pocas palabras de 1 caracter en ingles: i, a, m (se debió obtener al convertir \"I'm\" a: \"i m\" con el proceso de limpieza) y otros casos similares por el estilo."
      ],
      "metadata": {
        "id": "plv2-7BY4XEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yTDZ0Rr86CUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6624cd1-4dab-4441-f6b2-5252c1477b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del diccionario: 3261\n"
          ]
        }
      ],
      "source": [
        "# b.\tIndica el tamaño del vocabulario generado.\n",
        "\n",
        "# ******* Inicia la sección de agregar código: ***********\n",
        "\n",
        "# Mostramos la cantidad de palabras únicas en el diccionario\n",
        "print('Longitud del diccionario:', len(midicc))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDa4EhTqrw15"
      },
      "source": [
        "c.\t¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Principalmente para evitar fuga de datos (data leakage), ya que si usáramos los conjuntos de validación o prueba para generar el vocabulario, estaríamos \"contaminando\" nuestro modelo con información que no debería conocer durante el entrenamiento. Esto podría llevar a un sobreajuste y a una evaluación poco realista del rendimiento del modelo.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7ykjxQI3rpxx"
      },
      "outputs": [],
      "source": [
        "# d.\tCon el vocabulario generado, filtra los conjuntos de entrenamiento,\n",
        "#     validación y prueba para que todos los comentarios usen solamente las\n",
        "#     palabras de este vocabulario.\n",
        "\n",
        "#     Llamar train_x, val_x y test_x a estos tres conjuntos.\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "train_x = []\n",
        "for ss in x_train:\n",
        "  train_x.append([w for w in ss if w in midicc])\n",
        "\n",
        "val_x = []\n",
        "for ss in x_val:\n",
        "  val_x.append([w for w in ss if w in midicc])\n",
        "\n",
        "test_x = []\n",
        "for ss in x_test:\n",
        "  test_x.append([w for w in ss if w in midicc])\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iYF2RGuPtQTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45999e17-509b-427e-c314-cd881c37eda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['co', 'star', 'not', 'fare', 'much', 'well', 'people', 'like', 'morgan', 'freeman', 'jonah', 'hill', 'ed', 'helm', 'waste']\n",
            "['tonight', 'elk', 'filet', 'special', 'suck']\n",
            "['pay', 'bill', 'not', 'tip', 'feel', 'server', 'terrible', 'job']\n",
            "['call', 'steakhouse', 'not', 'properly', 'cook', 'steak', 'not', 'understand']\n",
            "['however', 'keypad', 'tinny', 'sometimes', 'reach', 'wrong', 'button']\n"
          ]
        }
      ],
      "source": [
        "# Vemos el resultado de los primeros comentarios del conjunto de entrenamiento:\n",
        "\n",
        "for ss in train_x[0:5]:\n",
        "  print(ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS0Hxj25vTWh"
      },
      "source": [
        "# **Pregunta - 5:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHHAza5_P5Z"
      },
      "source": [
        "\n",
        "#### **Incluye aquí un resumen de las características y diferencias que tiene al menos los tres modelos de OpenAI indicados: \"text-embedding-3-small\", \"text-embedding-3-large\" y \"text-embedding-ada-002\".**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTI9xSgF_Xc8"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "1. text-embedding-3-small:\n",
        "- Es el modelo más reciente y eficiente\n",
        "- Genera embeddings de 1536 dimensiones\n",
        "- Ofrece un buen balance entre rendimiento y costo\n",
        "- Tiene un mejor rendimiento que ada-002 en la mayoría de las tareas\n",
        "- Es más rápido y económico que text-embedding-3-large\n",
        "\n",
        "2. text-embedding-3-large:\n",
        "- Es el modelo más potente y reciente\n",
        "- Genera embeddings de 3072 dimensiones\n",
        "- Ofrece el mejor rendimiento en tareas de búsqueda semántica\n",
        "- Es más costoso y requiere más recursos computacionales\n",
        "- Ideal para aplicaciones que requieren máxima precisión\n",
        "\n",
        "3. text-embedding-ada-002:\n",
        "- Es el modelo más antiguo de los tres\n",
        "- Genera embeddings de 1536 dimensiones\n",
        "- Fue el modelo estándar antes del lanzamiento de la serie 3\n",
        "- Tiene un rendimiento inferior a los modelos de la serie 3\n",
        "- Sigue siendo útil para aplicaciones básicas\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToqRl7fT_fn2"
      },
      "source": [
        "# **Pregunta - 6:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKqQk03oqoOD"
      },
      "source": [
        "#### **Diccionario clave-valor de palabras del diccionario y vectores embebidos.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UdK-jMfLxHLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e52ce1c-c2d3-468f-ed88-189f797963d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [00:29<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceso completado. Total de tokens utilizados: 5571\n",
            "Costo aproximado: $0.72423 USD\n",
            "Dimensión de los vectores: 3072\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "modelo = \"text-embedding-3-large\"\n",
        "\n",
        "# Generar embeddings y crear diccionario\n",
        "new_dictionary = {}\n",
        "total_tokens = 0\n",
        "\n",
        "# Procesamos por lotes para evitar límites de la API\n",
        "batch_size = 100\n",
        "listdicc = sorted(list(midicc))\n",
        "for i in tqdm(range(0, len(listdicc), batch_size)):\n",
        "    batch = listdicc[i:i+batch_size]\n",
        "\n",
        "    # Solicitar embeddings a la API\n",
        "    response = client.embeddings.create(\n",
        "        model=modelo,\n",
        "        input=batch\n",
        "    )\n",
        "\n",
        "    # Actualizar contador de tokens\n",
        "    total_tokens += response.usage.total_tokens\n",
        "\n",
        "    # Añadir al diccionario\n",
        "    for j, embedding in enumerate(response.data):\n",
        "        new_dictionary[batch[j]] = embedding.embedding\n",
        "\n",
        "# Guardar el diccionario\n",
        "with open(f'embeddings_{modelo.replace(\"-\", \"_\")}.pkl', 'wb') as f:\n",
        "    pickle.dump(new_dictionary, f)\n",
        "\n",
        "print(f\"Proceso completado. Total de tokens utilizados: {total_tokens}\")\n",
        "print(f\"Costo aproximado: ${total_tokens/1000 * 0.02 if modelo=='text-embedding-3-small' else total_tokens/1000 * 0.13 if modelo=='text-embedding-3-large' else total_tokens/1000 * 0.0001} USD\")\n",
        "print(f\"Dimensión de los vectores: {len(next(iter(new_dictionary.values())))}\")\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zg79eHAwquj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e379e1-8825-46c8-b870-0db73505c5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Palabra: 'aailiyah' → Vector: [0.005438161548227072, 0.006977107375860214, 0.004894760437309742, 0.02832324057817459, 0.0093498220667243]...\n",
            "2. Palabra: 'abandon' → Vector: [-0.007007264997810125, -0.015100497752428055, 0.003588845254853368, 0.007906953804194927, 0.014838914386928082]...\n",
            "3. Palabra: 'abhor' → Vector: [-0.033358048647642136, -0.050388824194669724, -0.0016424368368461728, -0.0007754170219413936, 0.011388050392270088]...\n",
            "4. Palabra: 'ability' → Vector: [-0.038174599409103394, 0.011189106851816177, 0.0041699339635670185, 0.006988861598074436, 0.010401018895208836]...\n",
            "5. Palabra: 'able' → Vector: [-0.02487010695040226, 0.03475460782647133, -0.010855298489332199, 0.01941598206758499, 0.019451282918453217]...\n"
          ]
        }
      ],
      "source": [
        "# guardar el nuevo vocabulario\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/MNA/NLP/Semana5'\n",
        "\n",
        "with open(os.path.join(folder_path, f'embeddings_{modelo.replace(\"-\", \"_\")}.pkl'), 'wb') as f:\n",
        "    pickle.dump(new_dictionary, f)\n",
        "\n",
        "np_dict = {k: np.array(v) for k, v in new_dictionary.items()}\n",
        "np.savez_compressed(\n",
        "    os.path.join(folder_path, f'embeddings_{modelo.replace(\"-\", \"_\")}.npz'),\n",
        "    embeddings=np_dict\n",
        ")\n",
        "\n",
        "# pintar los primeros registros\n",
        "pkl_path = f'{folder_path}/embeddings_{modelo.replace(\"-\", \"_\")}.pkl'\n",
        "\n",
        "# leemos el vector desde el almacenamiento\n",
        "with open(pkl_path, 'rb') as f:\n",
        "    vectores_midicc_guardados = pickle.load(f)\n",
        "\n",
        "for i, (word, vector) in enumerate(vectores_midicc_guardados.items()):\n",
        "    print(f\"{i+1}. Palabra: '{word}' → Vector: {vector[:5]}...\")\n",
        "    if i >= 4:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEjBokj0UYnN"
      },
      "source": [
        "**Los Tokens que se usaron de OpenAI al obtener los vectores de las 3261 palabras del diccionario fueron 5654 con el modelo: text-embedding-3-large**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "A_YNwBdX-9U0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4S7q0yR0Mpi"
      },
      "source": [
        "# **Pregunta - 7:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyeOrkoaC1eq"
      },
      "source": [
        "\n",
        "\n",
        "Generamos los vectores embebidos a partir de los conjuntos de entrenamiento, validación y prueba.\n",
        "\n",
        "Los llamaremos trainEmb, valEmb y testEmb, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y2MLTb4raZH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e109e4-79f4-42cb-b295-9131e2a4efe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3261"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(vectores_midicc_guardados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QIlJFVccfJ2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09bbc95-17f2-4232-cdbb-e3ff38d0ee8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(vectores_midicc_guardados['star'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wnfQpkxg0Usq"
      },
      "outputs": [],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "dimensiones_vectores = 3072\n",
        "\n",
        "\n",
        "def comentario_a_vector(comment, embedding_dict):\n",
        "    vectores = [embedding_dict[token] for token in comment if token in embedding_dict]\n",
        "\n",
        "    if len(vectores) == 0:\n",
        "        return np.zeros(len(next(iter(embedding_dict.values()))))\n",
        "    return np.mean(vectores, axis=0)\n",
        "\n",
        "# Procesar todos los comentarios\n",
        "trainEmb = np.array([comentario_a_vector(comentario, vectores_midicc_guardados) for comentario in train_x])\n",
        "valEmb   = np.array([comentario_a_vector(comentario, vectores_midicc_guardados) for comentario in val_x])\n",
        "testEmb  = np.array([comentario_a_vector(comentario, vectores_midicc_guardados) for comentario in test_x])\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "J3BBF96D0N8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7105dda-86a1-4023-ec23-3c2717570797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-Emb: (2100, 3072)\n",
            "Val-Emb: (450, 3072)\n",
            "Test-Emb: (450, 3072)\n"
          ]
        }
      ],
      "source": [
        "# Veamos las dimensiones de cada conjunto embebido:\n",
        "\n",
        "print(\"Train-Emb:\", trainEmb.shape)\n",
        "print(\"Val-Emb:\", valEmb.shape)\n",
        "print(\"Test-Emb:\", testEmb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibp1LA91CP_"
      },
      "source": [
        "# **Pregunta - 8:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxC9K0VnGOwG"
      },
      "source": [
        "\n",
        "Utiliza los modelos de regresión logística y bosque aleatorio (random forest) y encuentra sus desempeños.\n",
        "\n",
        "Compara los resultados con los de la semana anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OSG20SYJksqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c93d608f-e390-42bf-c916-784945e65f6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       solver penalty  max_iter     C  train_accuracy  val_accuracy  \\\n",
              "0       lbfgs      l2        50   0.1       83.666667     85.111111   \n",
              "1       lbfgs      l2        50   0.5       86.380952     87.111111   \n",
              "2       lbfgs      l2        50   1.0       87.095238     88.444444   \n",
              "3       lbfgs      l2        50   2.0       88.000000     88.888889   \n",
              "4       lbfgs      l2        50   4.0       89.142857     88.666667   \n",
              "5       lbfgs      l2        50   6.0       89.809524     88.222222   \n",
              "6       lbfgs      l2        50   8.0       89.857143     87.555556   \n",
              "7       lbfgs      l2        50  10.0       90.095238     87.555556   \n",
              "8       lbfgs      l2       100   0.1       83.666667     85.111111   \n",
              "9       lbfgs      l2       100   0.5       86.380952     87.111111   \n",
              "10      lbfgs      l2       100   1.0       87.095238     88.444444   \n",
              "11      lbfgs      l2       100   2.0       88.000000     88.888889   \n",
              "12      lbfgs      l2       100   4.0       89.142857     88.666667   \n",
              "13      lbfgs      l2       100   6.0       89.809524     88.222222   \n",
              "14      lbfgs      l2       100   8.0       89.857143     87.555556   \n",
              "15      lbfgs      l2       100  10.0       90.095238     87.555556   \n",
              "16  liblinear      l1        50   0.1       70.047619     70.000000   \n",
              "17  liblinear      l1        50   0.5       75.857143     75.555556   \n",
              "18  liblinear      l1        50   1.0       81.142857     81.333333   \n",
              "19  liblinear      l1        50   2.0       85.476190     83.111111   \n",
              "20  liblinear      l1        50   4.0       88.238095     84.888889   \n",
              "21  liblinear      l1        50   6.0       89.809524     86.000000   \n",
              "22  liblinear      l1        50   8.0       90.428571     85.555556   \n",
              "23  liblinear      l1        50  10.0       91.333333     85.777778   \n",
              "24  liblinear      l1       100   0.1       70.047619     70.000000   \n",
              "25  liblinear      l1       100   0.5       75.857143     75.555556   \n",
              "26  liblinear      l1       100   1.0       81.142857     81.333333   \n",
              "27  liblinear      l1       100   2.0       85.476190     83.111111   \n",
              "28  liblinear      l1       100   4.0       88.190476     84.888889   \n",
              "29  liblinear      l1       100   6.0       89.809524     86.000000   \n",
              "30  liblinear      l1       100   8.0       90.428571     85.555556   \n",
              "31  liblinear      l1       100  10.0       91.333333     85.777778   \n",
              "32  liblinear      l2        50   0.1       83.761905     85.333333   \n",
              "33  liblinear      l2        50   0.5       86.285714     87.111111   \n",
              "34  liblinear      l2        50   1.0       87.095238     88.444444   \n",
              "35  liblinear      l2        50   2.0       87.809524     88.888889   \n",
              "36  liblinear      l2        50   4.0       89.142857     88.666667   \n",
              "37  liblinear      l2        50   6.0       89.809524     88.222222   \n",
              "38  liblinear      l2        50   8.0       90.000000     88.000000   \n",
              "39  liblinear      l2        50  10.0       90.142857     87.777778   \n",
              "40  liblinear      l2       100   0.1       83.761905     85.333333   \n",
              "41  liblinear      l2       100   0.5       86.285714     87.111111   \n",
              "42  liblinear      l2       100   1.0       87.095238     88.444444   \n",
              "43  liblinear      l2       100   2.0       87.809524     88.888889   \n",
              "44  liblinear      l2       100   4.0       89.142857     88.666667   \n",
              "45  liblinear      l2       100   6.0       89.809524     88.222222   \n",
              "46  liblinear      l2       100   8.0       90.000000     88.000000   \n",
              "47  liblinear      l2       100  10.0       90.142857     87.777778   \n",
              "\n",
              "    train_accuracy - val_accuracy  \n",
              "0                       -1.444444  \n",
              "1                       -0.730159  \n",
              "2                       -1.349206  \n",
              "3                       -0.888889  \n",
              "4                        0.476190  \n",
              "5                        1.587302  \n",
              "6                        2.301587  \n",
              "7                        2.539683  \n",
              "8                       -1.444444  \n",
              "9                       -0.730159  \n",
              "10                      -1.349206  \n",
              "11                      -0.888889  \n",
              "12                       0.476190  \n",
              "13                       1.587302  \n",
              "14                       2.301587  \n",
              "15                       2.539683  \n",
              "16                       0.047619  \n",
              "17                       0.301587  \n",
              "18                      -0.190476  \n",
              "19                       2.365079  \n",
              "20                       3.349206  \n",
              "21                       3.809524  \n",
              "22                       4.873016  \n",
              "23                       5.555556  \n",
              "24                       0.047619  \n",
              "25                       0.301587  \n",
              "26                      -0.190476  \n",
              "27                       2.365079  \n",
              "28                       3.301587  \n",
              "29                       3.809524  \n",
              "30                       4.873016  \n",
              "31                       5.555556  \n",
              "32                      -1.571429  \n",
              "33                      -0.825397  \n",
              "34                      -1.349206  \n",
              "35                      -1.079365  \n",
              "36                       0.476190  \n",
              "37                       1.587302  \n",
              "38                       2.000000  \n",
              "39                       2.365079  \n",
              "40                      -1.571429  \n",
              "41                      -0.825397  \n",
              "42                      -1.349206  \n",
              "43                      -1.079365  \n",
              "44                       0.476190  \n",
              "45                       1.587302  \n",
              "46                       2.000000  \n",
              "47                       2.365079  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44d1eb15-4d83-4303-9ac9-e2a1fef8167d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>solver</th>\n",
              "      <th>penalty</th>\n",
              "      <th>max_iter</th>\n",
              "      <th>C</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_accuracy - val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>83.666667</td>\n",
              "      <td>85.111111</td>\n",
              "      <td>-1.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>86.380952</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>-0.730159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.095238</td>\n",
              "      <td>88.444444</td>\n",
              "      <td>-1.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>88.888889</td>\n",
              "      <td>-0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>89.142857</td>\n",
              "      <td>88.666667</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>88.222222</td>\n",
              "      <td>1.587302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>89.857143</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>2.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>90.095238</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>2.539683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>83.666667</td>\n",
              "      <td>85.111111</td>\n",
              "      <td>-1.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>86.380952</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>-0.730159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.095238</td>\n",
              "      <td>88.444444</td>\n",
              "      <td>-1.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>88.888889</td>\n",
              "      <td>-0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>89.142857</td>\n",
              "      <td>88.666667</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>88.222222</td>\n",
              "      <td>1.587302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>89.857143</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>2.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>90.095238</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>2.539683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>70.047619</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.047619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>75.857143</td>\n",
              "      <td>75.555556</td>\n",
              "      <td>0.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>81.142857</td>\n",
              "      <td>81.333333</td>\n",
              "      <td>-0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>85.476190</td>\n",
              "      <td>83.111111</td>\n",
              "      <td>2.365079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>88.238095</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>3.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>90.428571</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>4.873016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>91.333333</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>5.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>70.047619</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.047619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>75.857143</td>\n",
              "      <td>75.555556</td>\n",
              "      <td>0.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>81.142857</td>\n",
              "      <td>81.333333</td>\n",
              "      <td>-0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>85.476190</td>\n",
              "      <td>83.111111</td>\n",
              "      <td>2.365079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>88.190476</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>3.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>3.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>90.428571</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>4.873016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>91.333333</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>5.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>83.761905</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>-1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>86.285714</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>-0.825397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.095238</td>\n",
              "      <td>88.444444</td>\n",
              "      <td>-1.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.809524</td>\n",
              "      <td>88.888889</td>\n",
              "      <td>-1.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>89.142857</td>\n",
              "      <td>88.666667</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>88.222222</td>\n",
              "      <td>1.587302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>90.142857</td>\n",
              "      <td>87.777778</td>\n",
              "      <td>2.365079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>83.761905</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>-1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>86.285714</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>-0.825397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.095238</td>\n",
              "      <td>88.444444</td>\n",
              "      <td>-1.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.809524</td>\n",
              "      <td>88.888889</td>\n",
              "      <td>-1.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>89.142857</td>\n",
              "      <td>88.666667</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.809524</td>\n",
              "      <td>88.222222</td>\n",
              "      <td>1.587302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>90.142857</td>\n",
              "      <td>87.777778</td>\n",
              "      <td>2.365079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44d1eb15-4d83-4303-9ac9-e2a1fef8167d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44d1eb15-4d83-4303-9ac9-e2a1fef8167d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44d1eb15-4d83-4303-9ac9-e2a1fef8167d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43aeea8d-50dc-4050-989a-ea83f74d6398\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43aeea8d-50dc-4050-989a-ea83f74d6398')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43aeea8d-50dc-4050-989a-ea83f74d6398 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_45072840-6f35-4262-a232-ade664be312b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_resultados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_45072840-6f35-4262-a232-ade664be312b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_resultados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultados",
              "summary": "{\n  \"name\": \"df_resultados\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"solver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"liblinear\",\n          \"lbfgs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"penalty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"l1\",\n          \"l2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_iter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 50,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5087731989546045,\n        \"min\": 0.1,\n        \"max\": 10.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.931131733295446,\n        \"min\": 70.04761904761905,\n        \"max\": 91.33333333333333,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          83.66666666666667,\n          86.28571428571429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.43686311623785,\n        \"min\": 70.0,\n        \"max\": 88.88888888888889,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          85.11111111111111,\n          87.1111111111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy - val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0601380519458923,\n        \"min\": -1.5714285714285836,\n        \"max\": 5.555555555555557,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          -1.4444444444444429,\n          3.80952380952381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "solver_list = ['lbfgs', 'liblinear']\n",
        "penalty_list = ['l1', 'l2']\n",
        "max_iter_list = [50, 100]\n",
        "C_list = [0.1, 0.5, 1.0, 2.0, 4.0, 6.0, 8.0, 10.0]\n",
        "solver_penalty_combinatons = ['lbfgs-l2', 'lbfgs-None', 'liblinear-l1', 'liblinear-l2']\n",
        "resultados = []\n",
        "\n",
        "for a in range(len(solver_list)):\n",
        "  for b in range(len(penalty_list)):\n",
        "    for c in range(len(max_iter_list)):\n",
        "      for d in range(len(C_list)):\n",
        "        if(solver_list[a]+'-'+penalty_list[b] in solver_penalty_combinatons):\n",
        "          modeloLREmb = LogisticRegression(solver=solver_list[a], penalty=penalty_list[b], max_iter=max_iter_list[c], C=C_list[d])\n",
        "          modeloLREmb.fit(trainEmb, y_train)\n",
        "\n",
        "          resultados.append({\n",
        "              'solver': solver_list[a],\n",
        "              'penalty': penalty_list[b],\n",
        "              'max_iter': max_iter_list[c],\n",
        "              'C': C_list[d],\n",
        "              'train_accuracy': (100*modeloLREmb.score(trainEmb, y_train)),\n",
        "              'val_accuracy': (100*modeloLREmb.score(valEmb, y_val)),\n",
        "              'train_accuracy - val_accuracy': (100*modeloLREmb.score(trainEmb, y_train)) - (100*modeloLREmb.score(valEmb, y_val))\n",
        "          })\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "df_resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcjIVLPqNXGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2ca70c62-52f5-497e-b932-226d12f5206f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nparam_grid = [\\n    {\\n        \\'solver\\': [\\'liblinear\\'],\\n        \\'penalty\\': [\\'l1\\', \\'l2\\'],\\n        \\'C\\': [0.1, 0.5, 1.0, 2.0, 4.0],\\n        \\'max_iter\\': [50, 100]\\n    },\\n    {\\n        \\'solver\\': [\\'lbfgs\\'],\\n        \\'penalty\\': [\\'l2\\'],\\n        \\'C\\': [0.1, 0.5, 1.0, 2.0, 4.0],\\n        \\'max_iter\\': [50, 100]\\n    }\\n]\\n\\n\\nmodeloLREmb2 = LogisticRegression()\\ngrid_search = GridSearchCV(estimator=modeloLREmb2, param_grid=param_grid, cv=3, scoring=\\'accuracy\\')\\n\\ngrid_search.fit(trainEmb, y_train)\\n\\n\\nresultados = pd.DataFrame(grid_search.cv_results_)\\n\\n\\nfor mean, std, params in zip(\\n    resultados[\\'mean_test_score\\'],\\n    resultados[\\'std_test_score\\'],\\n    resultados[\\'params\\']\\n):\\n  print(f\"{mean:.4f} (+/-{std:.4f}) para {params}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "### GridSearchCV para la busqueda hiperparametros de LR ########\n",
        "\n",
        "'''\n",
        "param_grid = [\n",
        "    {\n",
        "        'solver': ['liblinear'],\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'C': [0.1, 0.5, 1.0, 2.0, 4.0],\n",
        "        'max_iter': [50, 100]\n",
        "    },\n",
        "    {\n",
        "        'solver': ['lbfgs'],\n",
        "        'penalty': ['l2'],\n",
        "        'C': [0.1, 0.5, 1.0, 2.0, 4.0],\n",
        "        'max_iter': [50, 100]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "modeloLREmb2 = LogisticRegression()\n",
        "grid_search = GridSearchCV(estimator=modeloLREmb2, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "\n",
        "for mean, std, params in zip(\n",
        "    resultados['mean_test_score'],\n",
        "    resultados['std_test_score'],\n",
        "    resultados['params']\n",
        "):\n",
        "  print(f\"{mean:.4f} (+/-{std:.4f}) para {params}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ycwjD8ztGOL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f25fc7-cc57-4884-bfff-43957dd480b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: Train-accuracy: 87.81%\n",
            "LR: Val-accuracy: 89%\n",
            "----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       216\n",
            "           1       0.90      0.88      0.89       234\n",
            "\n",
            "    accuracy                           0.89       450\n",
            "   macro avg       0.89      0.89      0.89       450\n",
            "weighted avg       0.89      0.89      0.89       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# REGRESIÓN LOGÍSTICA:\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "modeloLREmbFinal = LogisticRegression(solver='liblinear', penalty='l2' , max_iter=100, C=2.0)\n",
        "modeloLREmbFinal.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "y_pred_val_lr = modeloLREmbFinal.predict(valEmb)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloLREmbFinal.score(trainEmb, y_train)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloLREmbFinal.score(valEmb, y_val)))\n",
        "print('----------------')\n",
        "\n",
        "\n",
        "print(classification_report(y_val, y_pred_val_lr))\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparando este modelo con el de la semana anterior (matrices de conteo y tf-idf), el hecho de usar embeddings mejoró el modelo, ahora la diferencia del accuracy entre los conjuntos de entrenamiento y validación es mucho menor**"
      ],
      "metadata": {
        "id": "A717rhPICVzZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4q9NTEzmS-XG",
        "outputId": "174125d6-30a1-4415-aeb6-2ce20f32190b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    n_estimators  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
              "0            100       10.0                  2                 1         sqrt   \n",
              "1            100       10.0                  2                 1         sqrt   \n",
              "2            100       10.0                  2                 1         log2   \n",
              "3            100       10.0                  2                 1         log2   \n",
              "4            100       10.0                  2                 2         sqrt   \n",
              "5            100       10.0                  2                 2         sqrt   \n",
              "6            100       10.0                  2                 2         log2   \n",
              "7            100       10.0                  2                 2         log2   \n",
              "8            100       10.0                  5                 1         sqrt   \n",
              "9            100       10.0                  5                 1         sqrt   \n",
              "10           100       10.0                  5                 1         log2   \n",
              "11           100       10.0                  5                 1         log2   \n",
              "12           100       10.0                  5                 2         sqrt   \n",
              "13           100       10.0                  5                 2         sqrt   \n",
              "14           100       10.0                  5                 2         log2   \n",
              "15           100       10.0                  5                 2         log2   \n",
              "16           100       20.0                  2                 1         sqrt   \n",
              "17           100       20.0                  2                 1         sqrt   \n",
              "18           100       20.0                  2                 1         log2   \n",
              "19           100       20.0                  2                 1         log2   \n",
              "20           100       20.0                  2                 2         sqrt   \n",
              "21           100       20.0                  2                 2         sqrt   \n",
              "22           100       20.0                  2                 2         log2   \n",
              "23           100       20.0                  2                 2         log2   \n",
              "24           100       20.0                  5                 1         sqrt   \n",
              "25           100       20.0                  5                 1         sqrt   \n",
              "26           100       20.0                  5                 1         log2   \n",
              "27           100       20.0                  5                 1         log2   \n",
              "28           100       20.0                  5                 2         sqrt   \n",
              "29           100       20.0                  5                 2         sqrt   \n",
              "30           100       20.0                  5                 2         log2   \n",
              "31           100       20.0                  5                 2         log2   \n",
              "32           100        NaN                  2                 1         sqrt   \n",
              "33           100        NaN                  2                 1         sqrt   \n",
              "34           100        NaN                  2                 1         log2   \n",
              "35           100        NaN                  2                 1         log2   \n",
              "36           100        NaN                  2                 2         sqrt   \n",
              "37           100        NaN                  2                 2         sqrt   \n",
              "38           100        NaN                  2                 2         log2   \n",
              "39           100        NaN                  2                 2         log2   \n",
              "40           100        NaN                  5                 1         sqrt   \n",
              "41           100        NaN                  5                 1         sqrt   \n",
              "42           100        NaN                  5                 1         log2   \n",
              "43           100        NaN                  5                 1         log2   \n",
              "44           100        NaN                  5                 2         sqrt   \n",
              "45           100        NaN                  5                 2         sqrt   \n",
              "46           100        NaN                  5                 2         log2   \n",
              "47           100        NaN                  5                 2         log2   \n",
              "48           200       10.0                  2                 1         sqrt   \n",
              "49           200       10.0                  2                 1         sqrt   \n",
              "50           200       10.0                  2                 1         log2   \n",
              "51           200       10.0                  2                 1         log2   \n",
              "52           200       10.0                  2                 2         sqrt   \n",
              "53           200       10.0                  2                 2         sqrt   \n",
              "54           200       10.0                  2                 2         log2   \n",
              "55           200       10.0                  2                 2         log2   \n",
              "56           200       10.0                  5                 1         sqrt   \n",
              "57           200       10.0                  5                 1         sqrt   \n",
              "58           200       10.0                  5                 1         log2   \n",
              "59           200       10.0                  5                 1         log2   \n",
              "60           200       10.0                  5                 2         sqrt   \n",
              "61           200       10.0                  5                 2         sqrt   \n",
              "62           200       10.0                  5                 2         log2   \n",
              "63           200       10.0                  5                 2         log2   \n",
              "64           200       20.0                  2                 1         sqrt   \n",
              "65           200       20.0                  2                 1         sqrt   \n",
              "66           200       20.0                  2                 1         log2   \n",
              "67           200       20.0                  2                 1         log2   \n",
              "68           200       20.0                  2                 2         sqrt   \n",
              "69           200       20.0                  2                 2         sqrt   \n",
              "70           200       20.0                  2                 2         log2   \n",
              "71           200       20.0                  2                 2         log2   \n",
              "72           200       20.0                  5                 1         sqrt   \n",
              "73           200       20.0                  5                 1         sqrt   \n",
              "74           200       20.0                  5                 1         log2   \n",
              "75           200       20.0                  5                 1         log2   \n",
              "76           200       20.0                  5                 2         sqrt   \n",
              "77           200       20.0                  5                 2         sqrt   \n",
              "78           200       20.0                  5                 2         log2   \n",
              "79           200       20.0                  5                 2         log2   \n",
              "80           200        NaN                  2                 1         sqrt   \n",
              "81           200        NaN                  2                 1         sqrt   \n",
              "82           200        NaN                  2                 1         log2   \n",
              "83           200        NaN                  2                 1         log2   \n",
              "84           200        NaN                  2                 2         sqrt   \n",
              "85           200        NaN                  2                 2         sqrt   \n",
              "86           200        NaN                  2                 2         log2   \n",
              "87           200        NaN                  2                 2         log2   \n",
              "88           200        NaN                  5                 1         sqrt   \n",
              "89           200        NaN                  5                 1         sqrt   \n",
              "90           200        NaN                  5                 1         log2   \n",
              "91           200        NaN                  5                 1         log2   \n",
              "92           200        NaN                  5                 2         sqrt   \n",
              "93           200        NaN                  5                 2         sqrt   \n",
              "94           200        NaN                  5                 2         log2   \n",
              "95           200        NaN                  5                 2         log2   \n",
              "\n",
              "    bootstrap  train_accuracy  val_accuracy  train_accuracy - val_accuracy  \n",
              "0        True       99.714286     87.111111                      12.603175  \n",
              "1       False       99.952381     86.000000                      13.952381  \n",
              "2        True       99.666667     86.000000                      13.666667  \n",
              "3       False       99.857143     86.222222                      13.634921  \n",
              "4        True       99.714286     86.666667                      13.047619  \n",
              "5       False       99.904762     86.222222                      13.682540  \n",
              "6        True       99.619048     85.333333                      14.285714  \n",
              "7       False       99.904762     86.000000                      13.904762  \n",
              "8        True       99.666667     83.777778                      15.888889  \n",
              "9       False       99.904762     86.000000                      13.904762  \n",
              "10       True       99.761905     85.111111                      14.650794  \n",
              "11      False       99.904762     84.222222                      15.682540  \n",
              "12       True       99.714286     86.888889                      12.825397  \n",
              "13      False       99.952381     85.777778                      14.174603  \n",
              "14       True       99.809524     83.777778                      16.031746  \n",
              "15      False       99.904762     84.888889                      15.015873  \n",
              "16       True      100.000000     84.444444                      15.555556  \n",
              "17      False      100.000000     85.777778                      14.222222  \n",
              "18       True      100.000000     84.444444                      15.555556  \n",
              "19      False      100.000000     83.777778                      16.222222  \n",
              "20       True      100.000000     84.000000                      16.000000  \n",
              "21      False      100.000000     85.111111                      14.888889  \n",
              "22       True      100.000000     84.666667                      15.333333  \n",
              "23      False      100.000000     84.888889                      15.111111  \n",
              "24       True      100.000000     85.777778                      14.222222  \n",
              "25      False      100.000000     86.666667                      13.333333  \n",
              "26       True      100.000000     85.777778                      14.222222  \n",
              "27      False      100.000000     85.555556                      14.444444  \n",
              "28       True       99.952381     85.333333                      14.619048  \n",
              "29      False      100.000000     86.000000                      14.000000  \n",
              "30       True      100.000000     83.333333                      16.666667  \n",
              "31      False      100.000000     86.444444                      13.555556  \n",
              "32       True      100.000000     86.444444                      13.555556  \n",
              "33      False      100.000000     85.555556                      14.444444  \n",
              "34       True      100.000000     84.000000                      16.000000  \n",
              "35      False      100.000000     82.888889                      17.111111  \n",
              "36       True       99.952381     86.222222                      13.730159  \n",
              "37      False      100.000000     85.555556                      14.444444  \n",
              "38       True      100.000000     86.000000                      14.000000  \n",
              "39      False      100.000000     85.333333                      14.666667  \n",
              "40       True      100.000000     86.888889                      13.111111  \n",
              "41      False      100.000000     86.000000                      14.000000  \n",
              "42       True      100.000000     84.666667                      15.333333  \n",
              "43      False      100.000000     84.888889                      15.111111  \n",
              "44       True       99.952381     84.222222                      15.730159  \n",
              "45      False      100.000000     85.555556                      14.444444  \n",
              "46       True      100.000000     83.777778                      16.222222  \n",
              "47      False      100.000000     84.444444                      15.555556  \n",
              "48       True       99.761905     87.111111                      12.650794  \n",
              "49      False       99.904762     85.555556                      14.349206  \n",
              "50       True       99.857143     85.555556                      14.301587  \n",
              "51      False       99.857143     86.666667                      13.190476  \n",
              "52       True       99.714286     87.777778                      11.936508  \n",
              "53      False       99.904762     88.000000                      11.904762  \n",
              "54       True       99.857143     85.333333                      14.523810  \n",
              "55      False       99.904762     86.222222                      13.682540  \n",
              "56       True       99.666667     87.333333                      12.333333  \n",
              "57      False       99.904762     86.000000                      13.904762  \n",
              "58       True       99.761905     85.777778                      13.984127  \n",
              "59      False       99.857143     85.777778                      14.079365  \n",
              "60       True       99.666667     87.111111                      12.555556  \n",
              "61      False       99.904762     88.666667                      11.238095  \n",
              "62       True       99.809524     86.666667                      13.142857  \n",
              "63      False       99.904762     87.555556                      12.349206  \n",
              "64       True      100.000000     86.888889                      13.111111  \n",
              "65      False      100.000000     87.333333                      12.666667  \n",
              "66       True      100.000000     84.000000                      16.000000  \n",
              "67      False      100.000000     86.888889                      13.111111  \n",
              "68       True      100.000000     88.444444                      11.555556  \n",
              "69      False      100.000000     87.777778                      12.222222  \n",
              "70       True      100.000000     84.888889                      15.111111  \n",
              "71      False      100.000000     87.555556                      12.444444  \n",
              "72       True      100.000000     86.000000                      14.000000  \n",
              "73      False      100.000000     87.333333                      12.666667  \n",
              "74       True      100.000000     86.000000                      14.000000  \n",
              "75      False      100.000000     86.666667                      13.333333  \n",
              "76       True      100.000000     86.444444                      13.555556  \n",
              "77      False      100.000000     87.111111                      12.888889  \n",
              "78       True      100.000000     88.000000                      12.000000  \n",
              "79      False      100.000000     86.444444                      13.555556  \n",
              "80       True      100.000000     85.777778                      14.222222  \n",
              "81      False      100.000000     87.555556                      12.444444  \n",
              "82       True      100.000000     86.000000                      14.000000  \n",
              "83      False      100.000000     87.333333                      12.666667  \n",
              "84       True      100.000000     86.888889                      13.111111  \n",
              "85      False      100.000000     88.222222                      11.777778  \n",
              "86       True      100.000000     86.888889                      13.111111  \n",
              "87      False      100.000000     85.777778                      14.222222  \n",
              "88       True      100.000000     86.000000                      14.000000  \n",
              "89      False      100.000000     87.333333                      12.666667  \n",
              "90       True      100.000000     86.222222                      13.777778  \n",
              "91      False      100.000000     85.777778                      14.222222  \n",
              "92       True      100.000000     86.444444                      13.555556  \n",
              "93      False      100.000000     87.333333                      12.666667  \n",
              "94       True      100.000000     86.222222                      13.777778  \n",
              "95      False      100.000000     86.444444                      13.555556  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18bfd10e-7ead-4129-938f-a0f6c3fee6f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_samples_split</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "      <th>max_features</th>\n",
              "      <th>bootstrap</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_accuracy - val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.714286</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>12.603175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>13.952381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.666667</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>13.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.634921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.714286</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>13.047619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.682540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.619048</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>14.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>13.904762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.666667</td>\n",
              "      <td>83.777778</td>\n",
              "      <td>15.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>13.904762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.761905</td>\n",
              "      <td>85.111111</td>\n",
              "      <td>14.650794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>84.222222</td>\n",
              "      <td>15.682540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.714286</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>12.825397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.174603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.809524</td>\n",
              "      <td>83.777778</td>\n",
              "      <td>16.031746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>15.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.444444</td>\n",
              "      <td>15.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.444444</td>\n",
              "      <td>15.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>83.777778</td>\n",
              "      <td>16.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.111111</td>\n",
              "      <td>14.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.666667</td>\n",
              "      <td>15.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>15.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>13.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>14.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>16.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>82.888889</td>\n",
              "      <td>17.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.730159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>14.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>13.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.666667</td>\n",
              "      <td>15.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>15.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>84.222222</td>\n",
              "      <td>15.730159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>83.777778</td>\n",
              "      <td>16.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.444444</td>\n",
              "      <td>15.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.761905</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>12.650794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>85.555556</td>\n",
              "      <td>14.301587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>13.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.714286</td>\n",
              "      <td>87.777778</td>\n",
              "      <td>11.936508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>11.904762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>85.333333</td>\n",
              "      <td>14.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.682540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.666667</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>13.904762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.761905</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>13.984127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.666667</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>12.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>88.666667</td>\n",
              "      <td>11.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.809524</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>13.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>12.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>13.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>13.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>88.444444</td>\n",
              "      <td>11.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.777778</td>\n",
              "      <td>12.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>15.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>12.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>13.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.111111</td>\n",
              "      <td>12.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.555556</td>\n",
              "      <td>12.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>13.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>88.222222</td>\n",
              "      <td>11.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.888889</td>\n",
              "      <td>13.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>85.777778</td>\n",
              "      <td>14.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>87.333333</td>\n",
              "      <td>12.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.222222</td>\n",
              "      <td>13.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.444444</td>\n",
              "      <td>13.555556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18bfd10e-7ead-4129-938f-a0f6c3fee6f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18bfd10e-7ead-4129-938f-a0f6c3fee6f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18bfd10e-7ead-4129-938f-a0f6c3fee6f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f478f89-6754-40b1-baec-e7b06d61d6d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f478f89-6754-40b1-baec-e7b06d61d6d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f478f89-6754-40b1-baec-e7b06d61d6d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7b60d33f-f39b-4c1c-bd73-116330ccfc0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_resultados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b60d33f-f39b-4c1c-bd73-116330ccfc0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_resultados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultados",
              "summary": "{\n  \"name\": \"df_resultados\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"n_estimators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 100,\n        \"max\": 200,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          200,\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.039526306789696,\n        \"min\": 10.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          20.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_samples_split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_samples_leaf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_features\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"log2\",\n          \"sqrt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bootstrap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10274192741042404,\n        \"min\": 99.61904761904762,\n        \"max\": 100.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          99.80952380952381,\n          99.95238095238095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2107292350006107,\n        \"min\": 82.88888888888889,\n        \"max\": 88.66666666666667,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          86.8888888888889,\n          86.44444444444444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy - val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2233584532732371,\n        \"min\": 11.23809523809524,\n        \"max\": 17.111111111111114,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          13.1111111111111,\n          13.682539682539684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "## Para iterar por fors por algunas posibilidades con Random Forest\n",
        "n_estimators_list = [100, 200]\n",
        "max_depth_list = [10, 20, None]\n",
        "min_samples_split_list = [2, 5]\n",
        "min_samples_leaf_list = [1, 2]\n",
        "max_features_list = ['sqrt', 'log2']\n",
        "bootstrap_list = [True, False]\n",
        "resultados = []\n",
        "\n",
        "for a in range(len(n_estimators_list)):\n",
        "  for b in range(len(max_depth_list)):\n",
        "    for c in range(len(min_samples_split_list)):\n",
        "      for d in range(len(min_samples_leaf_list)):\n",
        "        for e in range(len(max_features_list)):\n",
        "          for f in range(len(bootstrap_list)):\n",
        "            modeloLREmb = RandomForestClassifier(n_estimators=n_estimators_list[a], max_depth=max_depth_list[b], min_samples_split=min_samples_split_list[c],\n",
        "                                                 min_samples_leaf=min_samples_leaf_list[d], max_features=max_features_list[e], bootstrap=bootstrap_list[f])\n",
        "            modeloLREmb.fit(trainEmb, y_train)\n",
        "\n",
        "            resultados.append({\n",
        "                'n_estimators': n_estimators_list[a],\n",
        "                'max_depth': max_depth_list[b],\n",
        "                'min_samples_split': min_samples_split_list[c],\n",
        "                'min_samples_leaf': min_samples_leaf_list[d],\n",
        "                'max_features': max_features_list[e],\n",
        "                'bootstrap': bootstrap_list[f],\n",
        "                'train_accuracy': (100*modeloLREmb.score(trainEmb, y_train)),\n",
        "                'val_accuracy': (100*modeloLREmb.score(valEmb, y_val)),\n",
        "                'train_accuracy - val_accuracy': (100*modeloLREmb.score(trainEmb, y_train)) - (100*modeloLREmb.score(valEmb, y_val))\n",
        "            })\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "df_resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 10)"
      ],
      "metadata": {
        "id": "DVcu5ws5FSAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTpJaYrMw0PE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "aae4da3d-3d94-4fa1-e188-202ff7904384"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200],\\n    \\'max_depth\\': [10, 20, None],\\n    \\'min_samples_split\\': [2, 5],\\n    \\'min_samples_leaf\\': [1, 2],\\n    \\'max_features\\': [\\'sqrt\\', \\'log2\\'],\\n    \\'bootstrap\\': [True, False]\\n}\\n\\n\\nmodeloRFEmb2 = RandomForestClassifier()\\ngrid_search = GridSearchCV(estimator=modeloRFEmb2, param_grid=param_grid, cv=3, scoring=\\'accuracy\\')\\ngrid_search.fit(trainEmb, y_train)\\n\\n\\nresultados = pd.DataFrame(grid_search.cv_results_)\\n\\n\\nfor mean, std, params in zip(\\n    resultados[\\'mean_test_score\\'],\\n    resultados[\\'std_test_score\\'],\\n    resultados[\\'params\\']\\n):\\n  print(f\"{mean:.4f} (+/-{std:.4f}) para {params}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 263
        }
      ],
      "source": [
        "### GridSearchCV para la busqueda hiperparametros de RF ########\n",
        "'''\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "\n",
        "modeloRFEmb2 = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(estimator=modeloRFEmb2, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "resultados = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "\n",
        "for mean, std, params in zip(\n",
        "    resultados['mean_test_score'],\n",
        "    resultados['std_test_score'],\n",
        "    resultados['params']\n",
        "):\n",
        "  print(f\"{mean:.4f} (+/-{std:.4f}) para {params}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N4n70GHW0sl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6453265-e6bd-4f7e-ae58-2e8c9c1e84eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RF: Train-accuracy: 100.00%\n",
            "RF: Val-accuracy: 88.00%\n",
            "----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88       216\n",
            "           1       0.89      0.88      0.88       234\n",
            "\n",
            "    accuracy                           0.88       450\n",
            "   macro avg       0.88      0.88      0.88       450\n",
            "weighted avg       0.88      0.88      0.88       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# BOSQUE ALEATORIO (Random Forest):\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "modeloRFEmbFinal = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_leaf=2, min_samples_split=2, max_features='sqrt', bootstrap=False)\n",
        "modeloRFEmbFinal.fit(trainEmb, y_train)\n",
        "\n",
        "y_pred_val_rf = modeloRFEmbFinal.predict(valEmb)\n",
        "\n",
        "print('\\nRF: Train-accuracy: %.2f%%' % (100*modeloRFEmbFinal.score(trainEmb, y_train)))\n",
        "print('RF: Val-accuracy: %.2f%%' % (100*modeloRFEmbFinal.score(valEmb, y_val)))\n",
        "print('----------------')\n",
        "\n",
        "print(classification_report(y_val, y_pred_val_rf))\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Al usar el modelo de Random Forest e intentar con varios hiperparámetros se obtuvieron modelos sobrenetrenados (porque la diferencia de accuracy entre los conjuntos de validación y prueba siempre fue amplia, en promedio 15%) por lo que concluimos que el modelo de Random Forest usando los vectores promedio de los comentarios no es una buena solución para el análisis de este conjunto de datos.**\n",
        "\n",
        "**Comparando este modelo con el de la semana anterior (matrices de conteo y tf-idf), el hecho de usar embeddings no mejoró el modelo porque ahora la diferencia del accuracy entre los conjuntos de entrenamiento y validación es mucho mayor.**"
      ],
      "metadata": {
        "id": "vS_AS5ZrAxPB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDIiSHvg0_hm"
      },
      "source": [
        "# **Pregunta - 9:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJtALGZHrGk"
      },
      "source": [
        "\n",
        "\n",
        "Reporte del mejor modelo con el conjunto de Prueba (Test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ETv4VLjP1GYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70154418-330f-4ca1-c297-0b6b781e8b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-accuracy con el mejor modelo 85.56%\n",
            "\n",
            "Matriz de confusión con el mejor modelo:\n",
            "[[187  29]\n",
            " [ 36 198]]\n",
            "\n",
            "Matriz de confusión con el mejor modelo en proporciones:\n",
            "[[0.41555556 0.06444444]\n",
            " [0.08       0.44      ]]\n",
            "\n",
            "Classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       216\n",
            "           1       0.87      0.85      0.86       234\n",
            "\n",
            "    accuracy                           0.86       450\n",
            "   macro avg       0.86      0.86      0.86       450\n",
            "weighted avg       0.86      0.86      0.86       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "mejor_modelo_emb = modeloLREmbFinal\n",
        "\n",
        "print('Test-accuracy con el mejor modelo %.2f%%' % (100*mejor_modelo_emb.score(testEmb, y_test)))\n",
        "\n",
        "pred = mejor_modelo_emb.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
        "\n",
        "print('\\nMatriz de confusión con el mejor modelo en proporciones:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]) / pred.shape[0])\n",
        "\n",
        "\n",
        "print('\\nClassification_report:')\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbhBUBKJp1MB"
      },
      "source": [
        "# **Pregunta - 10:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3zPSi-H7p6ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fad686d-f85e-486a-94d7-a7a9f59f112c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:31<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceso completado. Total de tokens utilizados: 49375\n",
            "Costo aproximado: $6.41875 USD\n",
            "Dimensión de los vectores: 3072\n"
          ]
        }
      ],
      "source": [
        "# Incluye todas las líneas de código y celdas que consideres adecuadas para este ejercicio.\n",
        "\n",
        "\n",
        "whole_comments = {}\n",
        "\n",
        "totalcomments = sorted(list(X))\n",
        "for i in tqdm(range(0, len(totalcomments), batch_size)):\n",
        "    batch = totalcomments[i:i+batch_size]\n",
        "\n",
        "    # Solicitar embeddings a la API\n",
        "    response = client.embeddings.create(\n",
        "        model=modelo,\n",
        "        input=batch\n",
        "    )\n",
        "\n",
        "    # Actualizar contador de tokens\n",
        "    total_tokens += response.usage.total_tokens\n",
        "\n",
        "    # Añadir al diccionario\n",
        "    for j, embedding in enumerate(response.data):\n",
        "        whole_comments[batch[j]] = embedding.embedding\n",
        "\n",
        "# Guardar el diccionario\n",
        "with open(f'embeddings_{modelo.replace(\"-\", \"_\")}.pkl', 'wb') as f:\n",
        "    pickle.dump(whole_comments, f)\n",
        "\n",
        "print(f\"Proceso completado. Total de tokens utilizados: {total_tokens}\")\n",
        "print(f\"Costo aproximado: ${total_tokens/1000 * 0.02 if modelo=='text-embedding-3-small' else total_tokens/1000 * 0.13 if modelo=='text-embedding-3-large' else total_tokens/1000 * 0.0001} USD\")\n",
        "print(f\"Dimensión de los vectores: {len(next(iter(whole_comments.values())))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_comments_file_name = 'whole_comments.pkl'"
      ],
      "metadata": {
        "id": "8fQ8-M5s-IHH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Los Tokens que se usaron de OpenAI al obtener los vectores de los 3000 comentarios originales fueron 43804 con el modelo: text-embedding-3-large. (Del uso anterior fueron 5654, restados al total de 49458)**\n",
        "\n"
      ],
      "metadata": {
        "id": "3KHhdOL6TSqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Mogr4IRcEAoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#len(whole_comments[\"Works great.\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q6oAZ3zIq1N",
        "outputId": "82b0e41a-6c5f-4c2e-c874-5b2caba11502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# guardar los comenarios\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/MNA/NLP/Semana5'\n",
        "\n",
        "with open(os.path.join(folder_path, f'embeddings_all-comments_{modelo.replace(\"-\", \"_\")}.pkl'), 'wb') as f:\n",
        "    pickle.dump(whole_comments, f)\n",
        "\n",
        "np_dict = {k: np.array(v) for k, v in whole_comments.items()}\n",
        "np.savez_compressed(\n",
        "    os.path.join(folder_path, f'embeddings_all-comments_{modelo.replace(\"-\", \"_\")}.npz'),\n",
        "    embeddings=np_dict\n",
        ")\n",
        "\n",
        "# pintar los primeros registros\n",
        "pkl_path = f'{folder_path}/embeddings_all-comments_{modelo.replace(\"-\", \"_\")}.pkl'\n",
        "\n",
        "# leemos el vector desde el almacenamiento\n",
        "with open(pkl_path, 'rb') as f:\n",
        "    embededd_comments_guardados = pickle.load(f)\n",
        "\n",
        "for i, (word, vector) in enumerate(embededd_comments_guardados.items()):\n",
        "    print(f\"{i+1}. Palabra: '{word}' → Vector: {vector[:5]}...\")\n",
        "    if i >= 4:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "BKnsuCQp-G18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2fb7f6-46d1-4e8d-f6f3-73631c49125f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Palabra: '!....THE OWNERS REALLY REALLY need to quit being soooooo cheap let them wrap my freaking sandwich in two papers not one!' → Vector: [-0.004280888009816408, -0.02210772968828678, -0.011260264553129673, -0.003191554918885231, 0.02141973003745079]...\n",
            "2. Palabra: '!I definitly recommend!!' → Vector: [0.000992166344076395, 0.06502792984247208, -0.015409225597977638, -0.005493796430528164, 0.009707646444439888]...\n",
            "3. Palabra: '#1 It Works - #2 It is Comfortable.' → Vector: [0.024443162605166435, 0.0013488702243193984, -0.015221795998513699, -0.004528934136033058, -0.00034104957012459636]...\n",
            "4. Palabra: '$50 Down the drain.' → Vector: [-0.008708203211426735, -0.005339101422578096, 0.010597795248031616, -0.036923427134752274, -0.016009263694286346]...\n",
            "5. Palabra: '& That movie was bad.' → Vector: [-0.03363950923085213, 0.002494657412171364, -0.007229902781546116, 0.021785197779536247, -0.0013044518418610096]...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_comments, x_val_and_test_comments, y_train_comments, y_val_and_test_comments = train_test_split(X, Y, train_size=.70, shuffle=True, random_state=1)\n",
        "x_val_comments, x_test_comments, y_val_comments, y_test_comments = train_test_split(x_val_and_test_comments, y_val_and_test_comments, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "\n",
        "print('X,y Train:', len(x_train_comments), len(y_train_comments))\n",
        "print('X,y Val:', len(x_val_comments), len(y_val_comments))\n",
        "print('X,y Test', len(x_test_comments), len(y_test_comments))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldOBfcrV_aEb",
        "outputId": "9faa9ad6-1056-4bdb-9650-9ddcc6184ce4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Se genera en np array con los vectores embebidos de cada data set\n",
        "dimensiones_vectores = 3072\n",
        "\n",
        "\n",
        "#TRAIN\n",
        "trainEmbComments = []\n",
        "for comment in x_train_comments:\n",
        "    if comment in embededd_comments_guardados:\n",
        "      trainEmbComments.append(embededd_comments_guardados[comment])\n",
        "      #print('Si estuvo' + comment)\n",
        "    else:\n",
        "      trainEmbComments.append(np.zeros(dimensiones_vectores))\n",
        "      #print('No estuvo' + comment)\n",
        "\n",
        "# Se convierte la lista a un array de Numpy\n",
        "trainEmbComments = np.array(trainEmbComments)\n",
        "\n",
        "#VAL\n",
        "valEmbComments = []\n",
        "for comment in x_val_comments:\n",
        "    if comment in embededd_comments_guardados:\n",
        "      valEmbComments.append(embededd_comments_guardados[comment])\n",
        "    else:\n",
        "      valEmbComments.append(np.zeros(dimensiones_vectores))\n",
        "\n",
        "# Se convierte la lista a un array de Numpy\n",
        "valEmbComments = np.array(valEmbComments)\n",
        "\n",
        "#TEST\n",
        "testEmbComments = []\n",
        "for comment in x_test_comments:\n",
        "    if comment in embededd_comments_guardados:\n",
        "      testEmbComments.append(embededd_comments_guardados[comment])\n",
        "    else:\n",
        "      testEmbComments.append(np.zeros(dimensiones_vectores))\n",
        "\n",
        "# Se convierte la lista a un array de Numpy\n",
        "testEmbComments = np.array(testEmbComments)"
      ],
      "metadata": {
        "id": "XmcW1yTlAuT2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver_list = ['lbfgs', 'liblinear']\n",
        "penalty_list = ['l1', 'l2']\n",
        "max_iter_list = [50, 100]\n",
        "C_list = [0.1, 0.5, 1.0, 2.0, 4.0, 6.0, 8.0, 10.0]\n",
        "solver_penalty_combinatons = ['lbfgs-l2', 'lbfgs-None', 'liblinear-l1', 'liblinear-l2']\n",
        "resultados = []\n",
        "\n",
        "for a in range(len(solver_list)):\n",
        "  for b in range(len(penalty_list)):\n",
        "    for c in range(len(max_iter_list)):\n",
        "      for d in range(len(C_list)):\n",
        "        if(solver_list[a]+'-'+penalty_list[b] in solver_penalty_combinatons):\n",
        "          modeloLREmb_10 = LogisticRegression(solver=solver_list[a], penalty=penalty_list[b], max_iter=max_iter_list[c], C=C_list[d])\n",
        "          modeloLREmb_10.fit(trainEmbComments, y_train_comments)\n",
        "\n",
        "          resultados.append({\n",
        "              'solver': solver_list[a],\n",
        "              'penalty': penalty_list[b],\n",
        "              'max_iter': max_iter_list[c],\n",
        "              'C': C_list[d],\n",
        "              'train_accuracy': (100*modeloLREmb_10.score(trainEmbComments, y_train_comments)),\n",
        "              'val_accuracy': (100*modeloLREmb_10.score(valEmbComments, y_val_comments)),\n",
        "              'train_accuracy - val_accuracy': (100*modeloLREmb_10.score(trainEmbComments, y_train_comments)) - (100*modeloLREmb_10.score(valEmbComments, y_val_comments))\n",
        "          })\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "df_resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fqed_eR2AIba",
        "outputId": "9fb8d66c-e93b-49a0-a846-49775cffe930"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       solver penalty  max_iter     C  train_accuracy  val_accuracy  \\\n",
              "0       lbfgs      l2        50   0.1       98.571429     98.888889   \n",
              "1       lbfgs      l2        50   0.5       98.809524     98.666667   \n",
              "2       lbfgs      l2        50   1.0       98.809524     98.888889   \n",
              "3       lbfgs      l2        50   2.0       98.904762     98.888889   \n",
              "4       lbfgs      l2        50   4.0       99.190476     98.666667   \n",
              "5       lbfgs      l2        50   6.0       99.285714     98.666667   \n",
              "6       lbfgs      l2        50   8.0       99.380952     98.666667   \n",
              "7       lbfgs      l2        50  10.0       99.476190     98.666667   \n",
              "8       lbfgs      l2       100   0.1       98.571429     98.888889   \n",
              "9       lbfgs      l2       100   0.5       98.809524     98.666667   \n",
              "10      lbfgs      l2       100   1.0       98.809524     98.888889   \n",
              "11      lbfgs      l2       100   2.0       98.904762     98.888889   \n",
              "12      lbfgs      l2       100   4.0       99.190476     98.666667   \n",
              "13      lbfgs      l2       100   6.0       99.285714     98.666667   \n",
              "14      lbfgs      l2       100   8.0       99.380952     98.666667   \n",
              "15      lbfgs      l2       100  10.0       99.476190     98.666667   \n",
              "16  liblinear      l1        50   0.1       88.095238     84.888889   \n",
              "17  liblinear      l1        50   0.5       96.333333     95.777778   \n",
              "18  liblinear      l1        50   1.0       97.428571     96.888889   \n",
              "19  liblinear      l1        50   2.0       98.333333     97.333333   \n",
              "20  liblinear      l1        50   4.0       98.952381     97.555556   \n",
              "21  liblinear      l1        50   6.0       99.333333     98.222222   \n",
              "22  liblinear      l1        50   8.0       99.380952     98.444444   \n",
              "23  liblinear      l1        50  10.0       99.619048     98.000000   \n",
              "24  liblinear      l1       100   0.1       88.095238     84.888889   \n",
              "25  liblinear      l1       100   0.5       96.333333     95.777778   \n",
              "26  liblinear      l1       100   1.0       97.428571     96.888889   \n",
              "27  liblinear      l1       100   2.0       98.333333     97.111111   \n",
              "28  liblinear      l1       100   4.0       98.952381     97.555556   \n",
              "29  liblinear      l1       100   6.0       99.333333     98.222222   \n",
              "30  liblinear      l1       100   8.0       99.380952     98.444444   \n",
              "31  liblinear      l1       100  10.0       99.619048     98.444444   \n",
              "32  liblinear      l2        50   0.1       98.571429     98.888889   \n",
              "33  liblinear      l2        50   0.5       98.809524     98.666667   \n",
              "34  liblinear      l2        50   1.0       98.809524     98.888889   \n",
              "35  liblinear      l2        50   2.0       98.904762     98.888889   \n",
              "36  liblinear      l2        50   4.0       99.190476     98.666667   \n",
              "37  liblinear      l2        50   6.0       99.285714     98.666667   \n",
              "38  liblinear      l2        50   8.0       99.380952     98.666667   \n",
              "39  liblinear      l2        50  10.0       99.476190     98.666667   \n",
              "40  liblinear      l2       100   0.1       98.571429     98.888889   \n",
              "41  liblinear      l2       100   0.5       98.809524     98.666667   \n",
              "42  liblinear      l2       100   1.0       98.809524     98.888889   \n",
              "43  liblinear      l2       100   2.0       98.904762     98.888889   \n",
              "44  liblinear      l2       100   4.0       99.190476     98.666667   \n",
              "45  liblinear      l2       100   6.0       99.285714     98.666667   \n",
              "46  liblinear      l2       100   8.0       99.380952     98.666667   \n",
              "47  liblinear      l2       100  10.0       99.476190     98.666667   \n",
              "\n",
              "    train_accuracy - val_accuracy  \n",
              "0                       -0.317460  \n",
              "1                        0.142857  \n",
              "2                       -0.079365  \n",
              "3                        0.015873  \n",
              "4                        0.523810  \n",
              "5                        0.619048  \n",
              "6                        0.714286  \n",
              "7                        0.809524  \n",
              "8                       -0.317460  \n",
              "9                        0.142857  \n",
              "10                      -0.079365  \n",
              "11                       0.015873  \n",
              "12                       0.523810  \n",
              "13                       0.619048  \n",
              "14                       0.714286  \n",
              "15                       0.809524  \n",
              "16                       3.206349  \n",
              "17                       0.555556  \n",
              "18                       0.539683  \n",
              "19                       1.000000  \n",
              "20                       1.396825  \n",
              "21                       1.111111  \n",
              "22                       0.936508  \n",
              "23                       1.619048  \n",
              "24                       3.206349  \n",
              "25                       0.555556  \n",
              "26                       0.539683  \n",
              "27                       1.222222  \n",
              "28                       1.396825  \n",
              "29                       1.111111  \n",
              "30                       0.936508  \n",
              "31                       1.174603  \n",
              "32                      -0.317460  \n",
              "33                       0.142857  \n",
              "34                      -0.079365  \n",
              "35                       0.015873  \n",
              "36                       0.523810  \n",
              "37                       0.619048  \n",
              "38                       0.714286  \n",
              "39                       0.809524  \n",
              "40                      -0.317460  \n",
              "41                       0.142857  \n",
              "42                      -0.079365  \n",
              "43                       0.015873  \n",
              "44                       0.523810  \n",
              "45                       0.619048  \n",
              "46                       0.714286  \n",
              "47                       0.809524  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aabc6ceb-c474-4cdd-b898-9a959238747a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>solver</th>\n",
              "      <th>penalty</th>\n",
              "      <th>max_iter</th>\n",
              "      <th>C</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_accuracy - val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98.571429</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.317460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>99.190476</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.285714</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.476190</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98.571429</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.317460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>99.190476</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.285714</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lbfgs</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.476190</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>88.095238</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>3.206349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96.333333</td>\n",
              "      <td>95.777778</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>97.428571</td>\n",
              "      <td>96.888889</td>\n",
              "      <td>0.539683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.333333</td>\n",
              "      <td>97.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.952381</td>\n",
              "      <td>97.555556</td>\n",
              "      <td>1.396825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>98.222222</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>0.936508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.619048</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>1.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>88.095238</td>\n",
              "      <td>84.888889</td>\n",
              "      <td>3.206349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>96.333333</td>\n",
              "      <td>95.777778</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>97.428571</td>\n",
              "      <td>96.888889</td>\n",
              "      <td>0.539683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.333333</td>\n",
              "      <td>97.111111</td>\n",
              "      <td>1.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.952381</td>\n",
              "      <td>97.555556</td>\n",
              "      <td>1.396825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>98.222222</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>0.936508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l1</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.619048</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.174603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98.571429</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.317460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>99.190476</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.285714</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.476190</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98.571429</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.317460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.5</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.809524</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>-0.079365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>4.0</td>\n",
              "      <td>99.190476</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>99.285714</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>8.0</td>\n",
              "      <td>99.380952</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>liblinear</td>\n",
              "      <td>l2</td>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>99.476190</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>0.809524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aabc6ceb-c474-4cdd-b898-9a959238747a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aabc6ceb-c474-4cdd-b898-9a959238747a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aabc6ceb-c474-4cdd-b898-9a959238747a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31c473d7-3ccb-456a-8f1b-a2884ed60a67\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31c473d7-3ccb-456a-8f1b-a2884ed60a67')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31c473d7-3ccb-456a-8f1b-a2884ed60a67 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_eac0ffc9-185b-4b6f-9434-e3914681fdf3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_resultados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eac0ffc9-185b-4b6f-9434-e3914681fdf3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_resultados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultados",
              "summary": "{\n  \"name\": \"df_resultados\",\n  \"rows\": 48,\n  \"fields\": [\n    {\n      \"column\": \"solver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"liblinear\",\n          \"lbfgs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"penalty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"l1\",\n          \"l2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_iter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 50,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5087731989546045,\n        \"min\": 0.1,\n        \"max\": 10.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2906683549477616,\n        \"min\": 88.09523809523809,\n        \"max\": 99.61904761904762,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          97.42857142857143,\n          98.95238095238095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.824427047145284,\n        \"min\": 84.88888888888889,\n        \"max\": 98.88888888888889,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          97.33333333333334,\n          98.88888888888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy - val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7315987542331716,\n        \"min\": -0.3174603174603021,\n        \"max\": 3.206349206349202,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          -0.3174603174603021,\n          0.1428571428571388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 10)"
      ],
      "metadata": {
        "id": "KTRGpoOtLKcg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloLREmb_10_final = LogisticRegression(solver='liblinear', penalty='l1' , max_iter=100, C=0.5)\n",
        "modeloLREmb_10_final.fit(trainEmbComments, y_train_comments)\n",
        "\n",
        "\n",
        "y_pred_val_comments_lr = modeloLREmb_10_final.predict(valEmbComments)\n",
        "\n",
        "print('LR: Train-accuracy: %.2f%%' % (100*modeloLREmb_10_final.score(trainEmbComments, y_train_comments)))\n",
        "print('LR: Val-accuracy: %2.f%%' % (100*modeloLREmb_10_final.score(valEmbComments, y_val_comments)))\n",
        "print('----------------')\n",
        "\n",
        "\n",
        "print(classification_report(y_val_comments, y_pred_val_comments_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEsKelkYN6mj",
        "outputId": "78622905-2734-4bf8-ba12-c9311f0d2bff"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: Train-accuracy: 96.33%\n",
            "LR: Val-accuracy: 96%\n",
            "----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       216\n",
            "           1       0.98      0.94      0.96       234\n",
            "\n",
            "    accuracy                           0.96       450\n",
            "   macro avg       0.96      0.96      0.96       450\n",
            "weighted avg       0.96      0.96      0.96       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para el modelo de Regresión Logística, comparando el uso de los vectores promedio y el uso de los vectores del comentario original, se obtuvieron resultados mejores al usar el embedding del comentario completo. Mejorando el accuracy de un 89% a un 96%. Una mejoría sustancial.**"
      ],
      "metadata": {
        "id": "pFWQhPx3Gh8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators_list = [100, 200]\n",
        "max_depth_list = [10, 20, None]\n",
        "min_samples_split_list = [2, 5]\n",
        "min_samples_leaf_list = [1, 2]\n",
        "max_features_list = ['sqrt', 'log2']\n",
        "bootstrap_list = [True, False]\n",
        "resultados = []\n",
        "\n",
        "for a in range(len(n_estimators_list)):\n",
        "  for b in range(len(max_depth_list)):\n",
        "    for c in range(len(min_samples_split_list)):\n",
        "      for d in range(len(min_samples_leaf_list)):\n",
        "        for e in range(len(max_features_list)):\n",
        "          for f in range(len(bootstrap_list)):\n",
        "            modeloLREmb = RandomForestClassifier(n_estimators=n_estimators_list[a], max_depth=max_depth_list[b], min_samples_split=min_samples_split_list[c],\n",
        "                                                 min_samples_leaf=min_samples_leaf_list[d], max_features=max_features_list[e], bootstrap=bootstrap_list[f])\n",
        "            modeloLREmb.fit(trainEmbComments, y_train_comments)\n",
        "\n",
        "            resultados.append({\n",
        "                'n_estimators': n_estimators_list[a],\n",
        "                'max_depth': max_depth_list[b],\n",
        "                'min_samples_split': min_samples_split_list[c],\n",
        "                'min_samples_leaf': min_samples_leaf_list[d],\n",
        "                'max_features': max_features_list[e],\n",
        "                'bootstrap': bootstrap_list[f],\n",
        "                'train_accuracy': (100*modeloLREmb.score(trainEmbComments, y_train_comments)),\n",
        "                'val_accuracy': (100*modeloLREmb.score(valEmbComments, y_val_comments)),\n",
        "                'train_accuracy - val_accuracy': (100*modeloLREmb.score(trainEmbComments, y_train_comments)) - (100*modeloLREmb.score(valEmbComments, y_val_comments))\n",
        "            })\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "df_resultados\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lwiOd5M6P7ir",
        "outputId": "fd31c8d8-e87c-46ef-96e0-53657834ed6e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    n_estimators  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
              "0            100       10.0                  2                 1         sqrt   \n",
              "1            100       10.0                  2                 1         sqrt   \n",
              "2            100       10.0                  2                 1         log2   \n",
              "3            100       10.0                  2                 1         log2   \n",
              "4            100       10.0                  2                 2         sqrt   \n",
              "5            100       10.0                  2                 2         sqrt   \n",
              "6            100       10.0                  2                 2         log2   \n",
              "7            100       10.0                  2                 2         log2   \n",
              "8            100       10.0                  5                 1         sqrt   \n",
              "9            100       10.0                  5                 1         sqrt   \n",
              "10           100       10.0                  5                 1         log2   \n",
              "11           100       10.0                  5                 1         log2   \n",
              "12           100       10.0                  5                 2         sqrt   \n",
              "13           100       10.0                  5                 2         sqrt   \n",
              "14           100       10.0                  5                 2         log2   \n",
              "15           100       10.0                  5                 2         log2   \n",
              "16           100       20.0                  2                 1         sqrt   \n",
              "17           100       20.0                  2                 1         sqrt   \n",
              "18           100       20.0                  2                 1         log2   \n",
              "19           100       20.0                  2                 1         log2   \n",
              "20           100       20.0                  2                 2         sqrt   \n",
              "21           100       20.0                  2                 2         sqrt   \n",
              "22           100       20.0                  2                 2         log2   \n",
              "23           100       20.0                  2                 2         log2   \n",
              "24           100       20.0                  5                 1         sqrt   \n",
              "25           100       20.0                  5                 1         sqrt   \n",
              "26           100       20.0                  5                 1         log2   \n",
              "27           100       20.0                  5                 1         log2   \n",
              "28           100       20.0                  5                 2         sqrt   \n",
              "29           100       20.0                  5                 2         sqrt   \n",
              "30           100       20.0                  5                 2         log2   \n",
              "31           100       20.0                  5                 2         log2   \n",
              "32           100        NaN                  2                 1         sqrt   \n",
              "33           100        NaN                  2                 1         sqrt   \n",
              "34           100        NaN                  2                 1         log2   \n",
              "35           100        NaN                  2                 1         log2   \n",
              "36           100        NaN                  2                 2         sqrt   \n",
              "37           100        NaN                  2                 2         sqrt   \n",
              "38           100        NaN                  2                 2         log2   \n",
              "39           100        NaN                  2                 2         log2   \n",
              "40           100        NaN                  5                 1         sqrt   \n",
              "41           100        NaN                  5                 1         sqrt   \n",
              "42           100        NaN                  5                 1         log2   \n",
              "43           100        NaN                  5                 1         log2   \n",
              "44           100        NaN                  5                 2         sqrt   \n",
              "45           100        NaN                  5                 2         sqrt   \n",
              "46           100        NaN                  5                 2         log2   \n",
              "47           100        NaN                  5                 2         log2   \n",
              "48           200       10.0                  2                 1         sqrt   \n",
              "49           200       10.0                  2                 1         sqrt   \n",
              "50           200       10.0                  2                 1         log2   \n",
              "51           200       10.0                  2                 1         log2   \n",
              "52           200       10.0                  2                 2         sqrt   \n",
              "53           200       10.0                  2                 2         sqrt   \n",
              "54           200       10.0                  2                 2         log2   \n",
              "55           200       10.0                  2                 2         log2   \n",
              "56           200       10.0                  5                 1         sqrt   \n",
              "57           200       10.0                  5                 1         sqrt   \n",
              "58           200       10.0                  5                 1         log2   \n",
              "59           200       10.0                  5                 1         log2   \n",
              "60           200       10.0                  5                 2         sqrt   \n",
              "61           200       10.0                  5                 2         sqrt   \n",
              "62           200       10.0                  5                 2         log2   \n",
              "63           200       10.0                  5                 2         log2   \n",
              "64           200       20.0                  2                 1         sqrt   \n",
              "65           200       20.0                  2                 1         sqrt   \n",
              "66           200       20.0                  2                 1         log2   \n",
              "67           200       20.0                  2                 1         log2   \n",
              "68           200       20.0                  2                 2         sqrt   \n",
              "69           200       20.0                  2                 2         sqrt   \n",
              "70           200       20.0                  2                 2         log2   \n",
              "71           200       20.0                  2                 2         log2   \n",
              "72           200       20.0                  5                 1         sqrt   \n",
              "73           200       20.0                  5                 1         sqrt   \n",
              "74           200       20.0                  5                 1         log2   \n",
              "75           200       20.0                  5                 1         log2   \n",
              "76           200       20.0                  5                 2         sqrt   \n",
              "77           200       20.0                  5                 2         sqrt   \n",
              "78           200       20.0                  5                 2         log2   \n",
              "79           200       20.0                  5                 2         log2   \n",
              "80           200        NaN                  2                 1         sqrt   \n",
              "81           200        NaN                  2                 1         sqrt   \n",
              "82           200        NaN                  2                 1         log2   \n",
              "83           200        NaN                  2                 1         log2   \n",
              "84           200        NaN                  2                 2         sqrt   \n",
              "85           200        NaN                  2                 2         sqrt   \n",
              "86           200        NaN                  2                 2         log2   \n",
              "87           200        NaN                  2                 2         log2   \n",
              "88           200        NaN                  5                 1         sqrt   \n",
              "89           200        NaN                  5                 1         sqrt   \n",
              "90           200        NaN                  5                 1         log2   \n",
              "91           200        NaN                  5                 1         log2   \n",
              "92           200        NaN                  5                 2         sqrt   \n",
              "93           200        NaN                  5                 2         sqrt   \n",
              "94           200        NaN                  5                 2         log2   \n",
              "95           200        NaN                  5                 2         log2   \n",
              "\n",
              "    bootstrap  train_accuracy  val_accuracy  train_accuracy - val_accuracy  \n",
              "0        True       99.904762     98.666667                       1.238095  \n",
              "1       False       99.952381     98.888889                       1.063492  \n",
              "2        True      100.000000     98.888889                       1.111111  \n",
              "3       False      100.000000     98.666667                       1.333333  \n",
              "4        True       99.904762     98.666667                       1.238095  \n",
              "5       False       99.952381     99.111111                       0.841270  \n",
              "6        True      100.000000     99.111111                       0.888889  \n",
              "7       False      100.000000     98.444444                       1.555556  \n",
              "8        True       99.904762     98.888889                       1.015873  \n",
              "9       False       99.952381     98.888889                       1.063492  \n",
              "10       True       99.952381     99.111111                       0.841270  \n",
              "11      False      100.000000     99.111111                       0.888889  \n",
              "12       True       99.952381     98.444444                       1.507937  \n",
              "13      False       99.952381     98.888889                       1.063492  \n",
              "14       True       99.952381     98.444444                       1.507937  \n",
              "15      False      100.000000     98.888889                       1.111111  \n",
              "16       True      100.000000     98.666667                       1.333333  \n",
              "17      False      100.000000     98.666667                       1.333333  \n",
              "18       True      100.000000     99.111111                       0.888889  \n",
              "19      False      100.000000     98.666667                       1.333333  \n",
              "20       True       99.952381     98.888889                       1.063492  \n",
              "21      False      100.000000     98.888889                       1.111111  \n",
              "22       True      100.000000     98.666667                       1.333333  \n",
              "23      False      100.000000     98.888889                       1.111111  \n",
              "24       True      100.000000     98.666667                       1.333333  \n",
              "25      False      100.000000     98.444444                       1.555556  \n",
              "26       True      100.000000     98.666667                       1.333333  \n",
              "27      False      100.000000     98.444444                       1.555556  \n",
              "28       True       99.952381     98.666667                       1.285714  \n",
              "29      False      100.000000     98.888889                       1.111111  \n",
              "30       True       99.952381     98.888889                       1.063492  \n",
              "31      False      100.000000     98.666667                       1.333333  \n",
              "32       True      100.000000     98.666667                       1.333333  \n",
              "33      False      100.000000     98.666667                       1.333333  \n",
              "34       True      100.000000     98.444444                       1.555556  \n",
              "35      False      100.000000     98.888889                       1.111111  \n",
              "36       True       99.952381     98.666667                       1.285714  \n",
              "37      False      100.000000     98.666667                       1.333333  \n",
              "38       True       99.952381     98.000000                       1.952381  \n",
              "39      False      100.000000     98.888889                       1.111111  \n",
              "40       True      100.000000     98.444444                       1.555556  \n",
              "41      False      100.000000     98.444444                       1.555556  \n",
              "42       True      100.000000     99.111111                       0.888889  \n",
              "43      False      100.000000     98.666667                       1.333333  \n",
              "44       True       99.952381     98.888889                       1.063492  \n",
              "45      False      100.000000     98.888889                       1.111111  \n",
              "46       True      100.000000     98.888889                       1.111111  \n",
              "47      False      100.000000     98.888889                       1.111111  \n",
              "48       True       99.952381     98.222222                       1.730159  \n",
              "49      False       99.952381     98.666667                       1.285714  \n",
              "50       True       99.952381     98.888889                       1.063492  \n",
              "51      False      100.000000     99.111111                       0.888889  \n",
              "52       True       99.857143     98.888889                       0.968254  \n",
              "53      False       99.952381     99.111111                       0.841270  \n",
              "54       True       99.904762     98.444444                       1.460317  \n",
              "55      False      100.000000     99.111111                       0.888889  \n",
              "56       True       99.952381     98.666667                       1.285714  \n",
              "57      False       99.952381     99.111111                       0.841270  \n",
              "58       True       99.952381     99.111111                       0.841270  \n",
              "59      False      100.000000     99.333333                       0.666667  \n",
              "60       True       99.904762     98.888889                       1.015873  \n",
              "61      False       99.952381     98.888889                       1.063492  \n",
              "62       True       99.952381     99.111111                       0.841270  \n",
              "63      False      100.000000     98.666667                       1.333333  \n",
              "64       True      100.000000     99.333333                       0.666667  \n",
              "65      False      100.000000     99.111111                       0.888889  \n",
              "66       True      100.000000     99.111111                       0.888889  \n",
              "67      False      100.000000     99.111111                       0.888889  \n",
              "68       True       99.952381     98.888889                       1.063492  \n",
              "69      False      100.000000     98.444444                       1.555556  \n",
              "70       True      100.000000     99.111111                       0.888889  \n",
              "71      False      100.000000     98.666667                       1.333333  \n",
              "72       True      100.000000     98.888889                       1.111111  \n",
              "73      False      100.000000     99.111111                       0.888889  \n",
              "74       True       99.952381     98.666667                       1.285714  \n",
              "75      False      100.000000     98.888889                       1.111111  \n",
              "76       True       99.904762     98.666667                       1.238095  \n",
              "77      False      100.000000     99.111111                       0.888889  \n",
              "78       True       99.952381     98.666667                       1.285714  \n",
              "79      False      100.000000     98.888889                       1.111111  \n",
              "80       True      100.000000     99.111111                       0.888889  \n",
              "81      False      100.000000     98.666667                       1.333333  \n",
              "82       True      100.000000     98.444444                       1.555556  \n",
              "83      False      100.000000     98.888889                       1.111111  \n",
              "84       True      100.000000     99.111111                       0.888889  \n",
              "85      False      100.000000     99.111111                       0.888889  \n",
              "86       True       99.952381     99.333333                       0.619048  \n",
              "87      False      100.000000     98.888889                       1.111111  \n",
              "88       True      100.000000     98.888889                       1.111111  \n",
              "89      False      100.000000     99.111111                       0.888889  \n",
              "90       True      100.000000     98.666667                       1.333333  \n",
              "91      False      100.000000     98.888889                       1.111111  \n",
              "92       True       99.952381     98.666667                       1.285714  \n",
              "93      False      100.000000     99.333333                       0.666667  \n",
              "94       True       99.952381     98.888889                       1.063492  \n",
              "95      False      100.000000     98.666667                       1.333333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fce5054b-4faf-45cc-b7a5-0d96ffa5cc47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_samples_split</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "      <th>max_features</th>\n",
              "      <th>bootstrap</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>train_accuracy - val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.507937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.507937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>1.952381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.222222</td>\n",
              "      <td>1.730159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.857143</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>0.968254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.460317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.841270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>200</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.444444</td>\n",
              "      <td>1.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.111111</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.333333</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>True</td>\n",
              "      <td>99.952381</td>\n",
              "      <td>98.888889</td>\n",
              "      <td>1.063492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>log2</td>\n",
              "      <td>False</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>98.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fce5054b-4faf-45cc-b7a5-0d96ffa5cc47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fce5054b-4faf-45cc-b7a5-0d96ffa5cc47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fce5054b-4faf-45cc-b7a5-0d96ffa5cc47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af2b2b5d-61ff-42b8-afda-b26fba3b7084\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af2b2b5d-61ff-42b8-afda-b26fba3b7084')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af2b2b5d-61ff-42b8-afda-b26fba3b7084 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ac5c176e-6c20-44b2-b6c0-a33e48a2eee2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_resultados')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ac5c176e-6c20-44b2-b6c0-a33e48a2eee2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_resultados');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_resultados",
              "summary": "{\n  \"name\": \"df_resultados\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"n_estimators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 100,\n        \"max\": 200,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          200,\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.039526306789696,\n        \"min\": 10.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          20.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_samples_split\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_samples_leaf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_features\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"log2\",\n          \"sqrt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bootstrap\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03156406705412136,\n        \"min\": 99.85714285714286,\n        \"max\": 100.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          99.95238095238095,\n          99.85714285714286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2568953775393451,\n        \"min\": 98.0,\n        \"max\": 99.33333333333333,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          98.66666666666667,\n          98.88888888888889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy - val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25520656537950814,\n        \"min\": 0.6190476190476204,\n        \"max\": 1.952380952380949,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.2380952380952408,\n          1.0634920634920633\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 10)"
      ],
      "metadata": {
        "id": "PN7BWHe_VQrq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloRFEmb_10_final = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', bootstrap=True)\n",
        "modeloRFEmb_10_final.fit(trainEmbComments, y_train_comments)\n",
        "\n",
        "y_pred_val_comments_rf = modeloRFEmb_10_final.predict(valEmbComments)\n",
        "\n",
        "print('\\nRF: Train-accuracy: %.2f%%' % (100*modeloRFEmb_10_final.score(trainEmbComments, y_train_comments)))\n",
        "print('RF: Val-accuracy: %.2f%%' % (100*modeloRFEmb_10_final.score(valEmbComments, y_val_comments)))\n",
        "print('----------------')\n",
        "\n",
        "print(classification_report(y_val_comments, y_pred_val_comments_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpY4hnJSRrsz",
        "outputId": "b1956d92-4fb3-4aba-ee0c-4923b4bce32f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RF: Train-accuracy: 99.90%\n",
            "RF: Val-accuracy: 98.44%\n",
            "----------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       216\n",
            "           1       0.98      0.99      0.99       234\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.98      0.98      0.98       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para el modelo de Random Forest, comparando el uso de los vectores promedio y el uso de los vectores del comentario original, se obtuvieron resultados mucho mejores al usar el embedding del comentario completo. Mejorando el accuracy de un 88% hasta un 98%. Pero lo más importante fue que el modelo ya no esta sobreentrenado.**"
      ],
      "metadata": {
        "id": "pl1TwbAuHqKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mejor_modelo_emb_comments = modeloLREmb_10_final\n",
        "\n",
        "print('Test-accuracy con el mejor modelo %.2f%%' % (100*mejor_modelo_emb.score(testEmbComments, y_test_comments)))\n",
        "\n",
        "pred = mejor_modelo_emb_comments.predict(testEmbComments)\n",
        "print('\\nMatriz de confusión con el mejor modelo:')\n",
        "print(confusion_matrix(y_test_comments, pred, labels=[0,1]))\n",
        "\n",
        "print('\\nMatriz de confusión con el mejor modelo en proporciones:')\n",
        "print(confusion_matrix(y_test_comments, pred, labels=[0,1]) / pred.shape[0])\n",
        "\n",
        "\n",
        "print('\\nClassification_report:')\n",
        "print(classification_report(y_test_comments, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQGDotWaWb7U",
        "outputId": "b5738b6e-f607-47c7-ddc7-6d848faf2995"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test-accuracy con el mejor modelo 98.67%\n",
            "\n",
            "Matriz de confusión con el mejor modelo:\n",
            "[[210   6]\n",
            " [  8 226]]\n",
            "\n",
            "Matriz de confusión con el mejor modelo en proporciones:\n",
            "[[0.46666667 0.01333333]\n",
            " [0.01777778 0.50222222]]\n",
            "\n",
            "Classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97       216\n",
            "           1       0.97      0.97      0.97       234\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.97      0.97      0.97       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkh2WfN1MC1"
      },
      "source": [
        "# **Pregunta - 11:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySFuDQtVuK5"
      },
      "source": [
        "\n",
        "\n",
        "Incluye tus comentarios finales de la actividad.\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "El trabajo nos ayudó a profundizar en el uso de herramientas externas para generar los embeddings.\n",
        "Cada miembro uso un modelo diferente o plataforma distinta para evaluar con cual obteníamos mejores resultados.\n",
        "En el caso de Hugging face, encontramos que el embedding era muy pequeño lo que terminó entregando resultados no tan precisos.\n",
        "En el caso de OpenAI, probamos con el modelo small y large, siendo este segundo el que generaba mas información para procesar y un porcentaje de accuracy mayor que el resto.\n",
        "\n",
        "Tambien encontramos algunas conclusiones a nivel de los modelos trabajados:\n",
        "\n",
        "1. El uso de los embeddings para los modelos de Regresión Logística y Random Forest mejora sustancialmente los resultados de accuracy hasta un 10% en ambos casos.\n",
        "2. El uso de los embeddings para el modelo de Random Forest elimina el sobreentrenamiento que se obtenía al utilizar el embedding promedio.\n",
        "3. Se obtuvieron mejores resultados con el modelo text-embedding-3-large (vectores de 3072 dimensiones) con respecto a text-embedding-3-small (vectores de 1536 dimensiones)y al modelo gratuito de HuggingFace (vectores de 384 dimensiones).\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgKHmQTbWJT1"
      },
      "source": [
        "# **Fin de la Actividad de Vectores Embebidos - OpenAI**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MfZZ0stLmWJN",
        "RS0Hxj25vTWh",
        "YCkh2WfN1MC1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}